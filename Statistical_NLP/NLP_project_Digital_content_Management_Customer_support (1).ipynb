{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6a24a9",
   "metadata": {},
   "source": [
    "## Part -1 : Digital content management using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f80db4",
   "metadata": {
    "id": "1iqtrlA5lU6l"
   },
   "source": [
    "##### DOMAIN: Digital content management\n",
    "##### CONTEXT: Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles,  etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "##### DATA DESCRIPTION: Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "\t8240 \"10s\" blogs (ages 13-17), \n",
    "\t8086 \"20s\" blogs(ages 23-27) and \n",
    "\t2994 \"30s\" blogs (ages 33-47)\n",
    "\n",
    "\tFor each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url link. \n",
    "\t\n",
    "\tLink to dataset: https://www.kaggle.com/rtatman/blog-authorship-corpus\n",
    "##### PROJECT OBJECTIVE: The need is to build a NLP classifier which can use input text parameters to determine the label/s of the blog.\n",
    "\n",
    "Steps and tasks:\n",
    "\t1. Import and analyse the data set.\n",
    "\t2. Perform data pre-processing on the data:\n",
    "\t\t• Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase.\n",
    "\t\t• Target/label merger and transformation\n",
    "\t\t• Train and test split\n",
    "\t\t• Vectorisation, etc.\n",
    "\t3. Design, train, tune and test the best text classifier.\n",
    "\t4. Display and explain detail the classification report\n",
    "\t5. Print the true vs predicted labels for any 5 entries from the dataset.\n",
    "\n",
    "Hint: The aim here Is to import the text, process it such a way that it can be taken as an inout to the ML/NN classifiers. Be analytical and experimental here in trying new \n",
    "approaches to design the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc60e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeAMUDrGmcYs",
    "outputId": "6506dbbc-0395-4699-8b58-5012632e17d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',  force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ee030",
   "metadata": {
    "id": "jYpZqX_NmznU"
   },
   "source": [
    "\n",
    "### Task #1 :: Import and analyse the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4e566",
   "metadata": {
    "id": "FLhYZToUDXse"
   },
   "source": [
    "The data set provided is around 800 MB and there are many text records to be processed. This data may not fit into memory and processing will take more time and needs some mechanism to process the data parallely. There are several ways to handle data which doesn't fit to memory.\n",
    "\n",
    "Modin is a python library that can be used to handle large datasets using parallelisation.  Dask is one more framework which can be used in this use case. Here modin is using dask as underlying framework.\n",
    "\n",
    "Note: There are several other ways like using python pool which brings in some kind of parallelism but here we need to take care of releasing the utilized back. In Pandas release memory back is not working as expected. We shall see the same in this notebook and we would add appropriate explanation and **comment** the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d60434",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8KOFG0yDW7q",
    "outputId": "fcc11736-1c08-41fe-9772-c3dbe681044c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modin[dask] in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
      "Requirement already satisfied: pandas==1.3.4 in /usr/local/lib/python3.7/dist-packages (from modin[dask]) (1.3.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from modin[dask]) (21.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from modin[dask]) (1.19.5)\n",
      "Requirement already satisfied: dask>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from modin[dask]) (2021.10.0)\n",
      "Requirement already satisfied: distributed>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from modin[dask]) (2021.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4->modin[dask]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.4->modin[dask]) (2018.9)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.22.0->modin[dask]) (2021.10.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2.22.0->modin[dask]) (1.2.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2.22.0->modin[dask]) (3.13)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2.22.0->modin[dask]) (2.0.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2.22.0->modin[dask]) (0.11.1)\n",
      "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (7.1.2)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (2.4.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (57.4.0)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (5.4.8)\n",
      "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (5.1.1)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (1.0.2)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (1.7.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.22.0->modin[dask]) (2.11.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->modin[dask]) (2.4.7)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2.22.0->modin[dask]) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.4->modin[dask]) (1.15.0)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.22.0->modin[dask]) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2.22.0->modin[dask]) (2.0.1)\n",
      "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser) (1.5.1)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser) (2018.9)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser) (2.8.2)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.7/dist-packages (from dateparser) (2019.12.20)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "## Uncomment if starting new runtime/instance in colab\n",
    "!pip install modin[dask]\n",
    "!pip install dateparser\n",
    "!pip install emoji --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93825c9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YX026Dks-2BB",
    "outputId": "0a18beb1-8016-42ac-d6c2-e98a8094541f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
      "time: 212 µs (started: 2021-10-31 10:53:29 +00:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf9d9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cl07sFMrm6QW",
    "outputId": "650633bb-a9e0-4bed-f5be-05cb6b59e168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.1 ms (started: 2021-10-31 10:53:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "### instead of using pandas we are using modin and hence commenting pandas import statement\n",
    "\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"  # Modin will use Dask\n",
    "\n",
    "from nltk import WordNetLemmatizer\n",
    "import re\n",
    "import unicodedata\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283d73b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHQ6YhG3m6TO",
    "outputId": "0a7cdf76-6898-4200-d510-f5672f5d56ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.5 s (started: 2021-10-31 10:53:59 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df = pd.read_table('/content/drive/MyDrive/MachineLearning/NLP/Project/Week3Project/blogtext_1.csv', header='infer', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d93b298",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFCZHQ0hyUdY",
    "outputId": "3153e408-ad63-4428-8434-d7d94feef08c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.43 ms (started: 2021-10-31 10:54:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "### considering entire dataset\n",
    "blog_df = blog_df\n",
    "\n",
    "#considering only subset of data - for testing the flow\n",
    "# blog_df = blog_df.iloc[0:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e78b5",
   "metadata": {
    "id": "R49tMMmBnPNs"
   },
   "source": [
    "  Checking the basic information on dataframe which is created from the blog dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db6368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TaiuPX25m6WN",
    "outputId": "0632088a-7083-4b2c-ff8c-a3bdd76b6ae5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'int'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'modin.pandas.dataframe.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  ---------------  ----- \n",
      " 0   id      681284 non-null  int64\n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64\n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: object(5), int64(2)\n",
      "memory usage: 36.4 MB\n",
      "time: 3.19 s (started: 2021-10-31 10:54:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9e5a7",
   "metadata": {
    "id": "fxPMcd-rnb0x"
   },
   "source": [
    "  There are 681284 blog in the dataset. Id column is of int datatype and looks like it can be ignored from analysis. Gender, topic and sign are of object data type and needs to be looked into as it is required to predict the lable/s. Text column is out input column which needs to be processed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfd7e1",
   "metadata": {
    "id": "thTAKjoOojFb"
   },
   "source": [
    "  Lets check few sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42317e16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "X_bYjcplm6Y6",
    "outputId": "d3be95b7-89bf-46ca-c45d-1dba6b215d4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622701</th>\n",
       "      <td>1651222</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>22,December,2002</td>\n",
       "      <td>Damn, Joe Strummer is dead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122873</th>\n",
       "      <td>3294192</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>Check this shit, it is amazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385785</th>\n",
       "      <td>3393874</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>Libra</td>\n",
       "      <td>18,June,2004</td>\n",
       "      <td>Yesterday, I drove around the area ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326292</th>\n",
       "      <td>861706</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>17,October,2003</td>\n",
       "      <td>Looks like I have another fan may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64941</th>\n",
       "      <td>2539230</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>02,June,2004</td>\n",
       "      <td>Omg dude we had the worst thundestorm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124474</th>\n",
       "      <td>1304830</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>Education</td>\n",
       "      <td>Libra</td>\n",
       "      <td>25,January,2004</td>\n",
       "      <td>who knows... Mitch, who are u?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431567</th>\n",
       "      <td>183163</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>18,June,2004</td>\n",
       "      <td>yesterday, i woke up to the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588338</th>\n",
       "      <td>1078410</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>05,January,2004</td>\n",
       "      <td>urlLink Phantom unveiling at CES -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28864</th>\n",
       "      <td>3737788</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>27,Junho,2004</td>\n",
       "      <td>Feeling   molto  relaxed  today, after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436999</th>\n",
       "      <td>3690862</td>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>19,June,2004</td>\n",
       "      <td>Bubble Bong Collective:     (Heheh suck...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  ...                                               text\n",
       "622701  1651222  ...              Damn, Joe Strummer is dead.          \n",
       "122873  3294192  ...                   Check this shit, it is amazin...\n",
       "385785  3393874  ...             Yesterday, I drove around the area ...\n",
       "326292   861706  ...               Looks like I have another fan may...\n",
       "64941   2539230  ...         Omg dude we had the worst thundestorm e...\n",
       "124474  1304830  ...            who knows... Mitch, who are u?         \n",
       "431567   183163  ...                   yesterday, i woke up to the s...\n",
       "588338  1078410  ...              urlLink Phantom unveiling at CES -...\n",
       "28864   3737788  ...         Feeling   molto  relaxed  today, after ...\n",
       "436999  3690862  ...         Bubble Bong Collective:     (Heheh suck...\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 842 ms (started: 2021-10-31 10:54:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f764d6",
   "metadata": {
    "id": "1W9i1gb5on5m"
   },
   "source": [
    "  As we can observe in the above dataframe, id column can be ignored. Gender is a text column and may be a binary representation of male and female. Age represents the age of bloggeer, as given in data description, there are range and which can be grouped to have better visualization. Topic column shows that on which topic the blog is written upon. sign seems to be star sign of the blogger. Date column is the date when blog was posted. This date column can be ignore from the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e01555",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMuPbw2ByO4P",
    "outputId": "e7ec55dc-ce53-495a-e086-8873b0563504"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.96 ms (started: 2021-10-31 10:54:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5f6f2",
   "metadata": {
    "id": "PZrmuaVepQpB"
   },
   "source": [
    "Shape of dataset shows that there are 681284 rows and 7 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0414c",
   "metadata": {
    "id": "Cv0NA6RPpW8A"
   },
   "source": [
    "Lets check for any null values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95736cac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQg9s_GBs5Py",
    "outputId": "ad263f30-699f-4249-9d94-929305ad0e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no Null values in the dataframe.\n",
      "time: 354 ms (started: 2021-10-31 10:54:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "if not blog_df.isnull().values.any():\n",
    "  print(\"There are no Null values in the dataframe.\")\n",
    "else:\n",
    "  print(\"There are null values observed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3f682",
   "metadata": {
    "id": "c7DffLDAp0D9"
   },
   "source": [
    "Lets check for unique values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60523fa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tFkXcbRs9qM",
    "outputId": "45e84c42-2343-417f-8fbe-771996aa5a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique columns in gender\n",
      "['male' 'female']\n",
      "\n",
      "Unique columns in topic\n",
      "['Student' 'InvestmentBanking' 'indUnk' 'Non-Profit' 'Banking' 'Education'\n",
      " 'Engineering' 'Science' 'Communications-Media' 'BusinessServices'\n",
      " 'Sports-Recreation' 'Arts' 'Internet' 'Museums-Libraries' 'Accounting'\n",
      " 'Technology' 'Law' 'Consulting' 'Automotive' 'Religion' 'Fashion'\n",
      " 'Publishing' 'Marketing' 'LawEnforcement-Security' 'HumanResources'\n",
      " 'Telecommunications' 'Military' 'Government' 'Transportation'\n",
      " 'Architecture' 'Advertising' 'Agriculture' 'Biotech' 'RealEstate'\n",
      " 'Manufacturing' 'Construction' 'Chemicals' 'Maritime' 'Tourism'\n",
      " 'Environment']\n",
      "\n",
      "Unique columns in sign\n",
      "['Leo' 'Aquarius' 'Aries' 'Capricorn' 'Gemini' 'Cancer' 'Sagittarius'\n",
      " 'Scorpio' 'Libra' 'Virgo' 'Taurus' 'Pisces']\n",
      "\n",
      "time: 1.46 s (started: 2021-10-31 10:54:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "listOfColumns = ['gender', 'topic', 'sign']\n",
    "for i in listOfColumns:\n",
    "  print(\"Unique columns in {}\".format(i))\n",
    "  print(blog_df[i].unique())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33bfd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wr_b-hpM1SEL",
    "outputId": "cedbeed9-835c-43d8-e039-aea37173da11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.52 ms (started: 2021-10-31 10:54:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df_for_analysis = blog_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249aec76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpWjaL5ErzdL",
    "outputId": "898f7e06-f523-4828-c5ae-6c91c4d0524b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002-06-04\n",
      "1970-01-01\n",
      "1970-01-01\n",
      "1970-01-01\n",
      "time: 142 ms (started: 2021-10-31 10:54:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "import dateparser\n",
    "\n",
    "def date_to_milliseconds(date_str):\n",
    "    \"\"\"Convert UTC date to milliseconds\n",
    "\n",
    "    If using offset strings add \"UTC\" to date string e.g. \"now UTC\", \"11 hours ago UTC\"\n",
    "\n",
    "    See dateparse docs for formats http://dateparser.readthedocs.io/en/latest/\n",
    "\n",
    "    :param date_str: date in readable format, i.e. \"January 01, 2018\", \"11 hours ago UTC\", \"now UTC\"\n",
    "    :type date_str: str\n",
    "    \"\"\"\n",
    "    try:\n",
    "      if (len(date_str.strip()) == 0):\n",
    "        return \"1970-01-01\"\n",
    "      else:\n",
    "        # get epoch value in UTC\n",
    "        epoch = datetime.utcfromtimestamp(0).replace(tzinfo=pytz.utc) \n",
    "        # parse our date string\n",
    "        d = dateparser.parse(date_str)\n",
    "        # if the date is not timezone aware apply UTC timezone\n",
    "        if d.tzinfo is None or d.tzinfo.utcoffset(d) is None: \n",
    "          d = d.replace(tzinfo=pytz.utc)\n",
    "        return d.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "      return \"1970-01-01\"\n",
    "      \n",
    "\n",
    "print(date_to_milliseconds(\"04,Juni,2002\"))\n",
    "print(date_to_milliseconds(\"\"))\n",
    "print(date_to_milliseconds(\"abcd\"))\n",
    "print(date_to_milliseconds(\"!@#!@#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a68b40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvjfZzc4tDKX",
    "outputId": "56d5a95d-a597-4e50-d50c-585f3b8e65a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.34 s (started: 2021-10-31 10:54:16 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df_for_analysis['date'] = blog_df_for_analysis.date.apply(date_to_milliseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65957b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D362Buy-iAQ1",
    "outputId": "cde41cfd-019e-4f20-ca89-54c2d479317a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.83 ms (started: 2021-10-31 10:54:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# blog_df_for_analysis.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13f645",
   "metadata": {
    "id": "aXaFRElne2qi"
   },
   "source": [
    "    Below cell is commented, it is having the date conversion function call where in different date are converted to a uniform format. This is used for EDA. The function is not used since we are using modin instead of pandas. Modin provides required multi processing. This cell is retained as an exmaple of splitting pandas dataframe and processing them parallely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf1ef5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZmwJiBoe1yh",
    "outputId": "3d0b43ae-ee91-4ab8-ceda-a7b838b8676b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.46 ms (started: 2021-10-31 10:54:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Below cell contained processing pandas dataframe by splitting them in rows. This is not required as we are using modin[dask].\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# def data_convertor(inputDf):\n",
    "#   inputDf['Converted_date'] = inputDf.date.apply(date_to_milliseconds)  \n",
    "#   return inputDf\n",
    "\n",
    "# from more_itertools import sliced\n",
    "# CHUNK_SIZE = 1000\n",
    "\n",
    "# index_slices = sliced(range(len(blog_df_for_analysis)), CHUNK_SIZE)\n",
    "\n",
    "# # NewBlof_df = pd.DataFrame()\n",
    "# listOdDf = []\n",
    "# for index_slice in index_slices:\n",
    "#   chunk = blog_df_for_analysis.iloc[index_slice][['date']]\n",
    "#   listOdDf.append(chunk)\n",
    "#   # print(chunk.shape)\n",
    "\n",
    "# with Pool(processes=6) as pool:\n",
    "#   date_result = pool.map(data_convertor, listOdDf) #text.split())\n",
    "\n",
    "# converted_date_blog_df = pd.concat(date_result)\n",
    "# blog_df_for_analysis['Converted_date'] = pd.to_datetime(converted_date_blog_df['Converted_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b0bcf",
   "metadata": {},
   "source": [
    "    We shall check the dataset based on date. we shall preprocess the date column which will aid us for producing graphical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76bfcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "_GasQ28wEMvs",
    "outputId": "1df3691e-beaa-44a7-f416-ec3d535f757f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: sort_values defaulting to pandas implementation.\n",
      "To request implementation, send an email to feature_requests@modin.org.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12min 56s (started: 2021-10-31 10:54:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df_for_analysis['date'] = pd.to_datetime(blog_df_for_analysis['date'], format='%Y-%m-%d')\n",
    "blog_df_for_analysis.date.dt.strftime('%Y').value_counts().plot(kind=\"bar\",figsize=(10, 5), title=\"Year VS Number Of blogs\", xlabel = \"year\", ylabel = \"number Of Blogs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b65a1",
   "metadata": {},
   "source": [
    "    The above graphs showe number of blogs written by users based on dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18222a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "N1d2Li2rKHAD",
    "outputId": "cf726d6b-40f0-42e0-9556-87d3d22ddf3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `crosstab` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.26 s (started: 2021-10-31 11:07:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "pd.crosstab(blog_df_for_analysis.date.dt.strftime('%Y'),blog_df_for_analysis['gender']).plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f88f3",
   "metadata": {},
   "source": [
    "    The above graph shows the number of graphs based on gender with year on X-Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e8669",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "xsR2qs_ZKYLs",
    "outputId": "490e1c0e-e101-46b8-ecc9-e20511e06c13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `crosstab` defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.05 s (started: 2021-10-31 11:07:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "pd.crosstab(blog_df_for_analysis.date.dt.strftime('%m'),blog_df_for_analysis['gender']).plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06eade",
   "metadata": {},
   "source": [
    "        The above graph shows the number of graphs based on gender with month on X-Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792aa55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "ZkOaSiy6Fsqh",
    "outputId": "99455065-7799-4afa-c2cf-a06732c703d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: sort_values defaulting to pandas implementation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.1 s (started: 2021-10-31 11:07:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df_for_analysis.date.dt.strftime('%m').value_counts().plot(kind=\"bar\",figsize=(10, 5), title=\"Month VS Number Of blogs\", xlabel = \"Month\", ylabel = \"number Of Blogs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e7188",
   "metadata": {},
   "source": [
    "    Plotting graph of month vs number of blogs. It looks like we are having more number of blogs written in the july month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa8368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "q4E-P2vEvBma",
    "outputId": "d577502e-ffe5-47cc-e9f7-77d3a7190fff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: sort_values defaulting to pandas implementation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.3 s (started: 2021-10-31 11:07:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df_for_analysis.age.value_counts().plot(kind=\"bar\",figsize=(10, 5), title=\"Age Vs Number of blogs\", xlabel = \"Age\", ylabel = \"number Of Blogs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf66b31",
   "metadata": {},
   "source": [
    "    By Above graph we can say that more number of young people are fond of blogging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4303a52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "fZV6E9pivgGj",
    "outputId": "d0fedafb-f292-4489-c5e5-649802b8df59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: sort_values defaulting to pandas implementation.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.11 s (started: 2021-10-31 11:07:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df_for_analysis.gender.value_counts().plot(kind=\"bar\",figsize=(10, 5), title=\"Gender Vs Number of blogs\", xlabel = \"Gender\", ylabel = \"number Of Blogs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272a556",
   "metadata": {},
   "source": [
    "    Both genders are having same interest in writing the blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd9dc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVF7pNGcxSVL",
    "outputId": "b7a07f7a-821f-485b-f6f4-b0128a76d7f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unique values in sign column ::  ['Leo' 'Aquarius' 'Aries' 'Capricorn' 'Gemini' 'Cancer' 'Sagittarius'\n",
      " 'Scorpio' 'Libra' 'Virgo' 'Taurus' 'Pisces']\n",
      "\n",
      " Unique values in topic column ::  ['Student' 'InvestmentBanking' 'indUnk' 'Non-Profit' 'Banking' 'Education'\n",
      " 'Engineering' 'Science' 'Communications-Media' 'BusinessServices'\n",
      " 'Sports-Recreation' 'Arts' 'Internet' 'Museums-Libraries' 'Accounting'\n",
      " 'Technology' 'Law' 'Consulting' 'Automotive' 'Religion' 'Fashion'\n",
      " 'Publishing' 'Marketing' 'LawEnforcement-Security' 'HumanResources'\n",
      " 'Telecommunications' 'Military' 'Government' 'Transportation'\n",
      " 'Architecture' 'Advertising' 'Agriculture' 'Biotech' 'RealEstate'\n",
      " 'Manufacturing' 'Construction' 'Chemicals' 'Maritime' 'Tourism'\n",
      " 'Environment']\n",
      "\n",
      " Unique values in gender column ::  ['male' 'female']\n",
      "time: 4.45 s (started: 2021-10-31 11:07:34 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\" Unique values in sign column :: \" , blog_df_for_analysis.sign.unique())\n",
    "print()\n",
    "print(\" Unique values in topic column :: \", blog_df_for_analysis.topic.unique())\n",
    "print()\n",
    "print(\" Unique values in gender column :: \", blog_df_for_analysis.gender.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9078dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "xpJKKW3AyiGt",
    "outputId": "e199b8da-25c6-4371-9799-d42a9dd13541"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681284 rows x 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  ...                                               text\n",
       "0       2059027  ...             Info has been found (+/- 100 pages,...\n",
       "1       2059027  ...             These are the team members:   Drewe...\n",
       "2       2059027  ...             In het kader van kernfusie op aarde...\n",
       "3       2059027  ...                   testing!!!  testing!!!          \n",
       "4       3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
       "...         ...  ...                                                ...\n",
       "681279  1713845  ...         Dear Susan,  I could write some really ...\n",
       "681280  1713845  ...         Dear Susan,  'I have the second yeast i...\n",
       "681281  1713845  ...         Dear Susan,  Your 'boyfriend' is fuckin...\n",
       "681282  1713845  ...         Dear Susan:    Just to clarify, I am as...\n",
       "681283  1713845  ...         Hey everybody...and Susan,  You might a...\n",
       "\n",
       "[681284 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 680 ms (started: 2021-10-31 11:07:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da2868",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "tG-_WeTIynbw",
    "outputId": "b1c57ff0-f5c4-424c-fb64-05ed3aaa7227"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `Series.hist_series` defaulting to pandas implementation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f226b818390>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.31 s (started: 2021-10-31 11:07:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "lens = blog_df_for_analysis.text.str.len()\n",
    "lens.hist(bins = np.arange(0,5000,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c515c2",
   "metadata": {},
   "source": [
    "    The above graphs shows the most blogs are having around 250 words. There are very less number of blogs which are having more than 4000 words. If we plot number of words v/s topic column that would give insight into the serious topic on which people have written lenghty blogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d316edb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhNmPbWQj_PO",
    "outputId": "bbaced29-9bba-4027-9cb7-ff45e4834d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing comments in comment text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 378 ms (started: 2021-10-31 11:07:41 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing comments in comment text:')\n",
    "blog_df_for_analysis['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626aaf1b",
   "metadata": {
    "id": "kPQsHI0WypGX"
   },
   "source": [
    "## Perform data pre-processing on the data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674f78d",
   "metadata": {
    "id": "QTss2vjPAKV5"
   },
   "source": [
    "### Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d020efa",
   "metadata": {
    "id": "wYjUeQseJz-4"
   },
   "source": [
    "    Next 2 cells has few function implementation which aids for data cleansing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1604b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsJjiZ9lX1lx",
    "outputId": "eb202eb1-e508-4a9a-ba43-f726e59041ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.         \n",
      "info have be find ( +/- 100 page , and 4.5 mb of .pdf file ) now i have to wait untill our team leader have process it and learn html .\n",
      "time: 3.6 s (started: 2021-10-31 11:07:41 +00:00)\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "    \n",
    "def lemmatize_sent(text): \n",
    "    # Text input is string, returns lowercased strings.\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(word_tokenize(text))]\n",
    "\n",
    "print((blog_df.text[0]))\n",
    "print(' '.join(lemmatize_sent(blog_df.text[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6adfbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xdMepTjytEP",
    "outputId": "b043f3e3-c696-466d-8ee1-03a8808bd937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 314 ms (started: 2021-10-31 11:07:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer #word stemmer class\n",
    "lemma = WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "class CleanUpData():\n",
    "  '''CleanUpData has few function to clean up input string\n",
    "  It has a function \n",
    "    1) To remove space\n",
    "    2) To remove special characters\n",
    "    3) To remove accented characters    \n",
    "    '''\n",
    "\n",
    "  def remove_non_english_words(blog):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(blog) if w.lower() in words or not w.isalpha())\n",
    "\n",
    "  def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "    \n",
    "  def lemmatize_sent(text):\n",
    "    # Text input is string, returns lowercased strings.\n",
    "    return \" \".join([wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) for word, tag in pos_tag(word_tokenize(text))])\n",
    "\n",
    "  def worker_wrapperr(arg):\n",
    "    word, pos = arg\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return wnl.lemmatize(word, pos)\n",
    "\n",
    "  #Below code is only required if we are not using modin. This use pool function.\n",
    "  def lemmed(text, cores=6):\n",
    "    # tweak cores as needed\n",
    "    argg = [(word.lower(), penn2morphy(tag)) for word, tag in pos_tag(word_tokenize(text))]\n",
    "    with Pool(processes=cores) as pool:\n",
    "        wnl = WordNetLemmatizer()\n",
    "        result = pool.map(CleanUpData.worker_wrapperr,  argg) #text.split())\n",
    "    return result\n",
    "\n",
    "  def remove_special_characters(text, remove_digits=False):\n",
    "    #Using regex\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "  def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "  def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "  def remove_emojis(text):\n",
    "    return emoji.demojize(blog_df.text[1].replace(':',''))\n",
    "\n",
    "  def remove_stop_words(text):\n",
    "    listOfWords = text.split(' ')\n",
    "    # print(listOfWords)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    rtext = ''\n",
    "    for word in text.split(' '):\n",
    "      # print(word)\n",
    "      if(word not in stop_words):\n",
    "        rtext = rtext + ' ' + word\n",
    "    return rtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08876665",
   "metadata": {
    "id": "ZYp8FjHjJBeJ"
   },
   "source": [
    "  Lets check the function which are written to cleanse the text in the dataframe. This would give us some idea on how cleansing work on the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63fb58c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IA_-4mqE5S1b",
    "outputId": "fea847f8-18b2-4528-9c91-13bd0a32c994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text ::                   i can't wait for things to get moving, i want out of here. im lookin forward to uni although it means another 3 years in england. it should be so much fun from my experiences of it so far and my brother's experiences. after uni though it will be another year i guess before i can move, as i'll need to work for 'bout that long to get some money. will be quite lonely i imagine as every1 will have moved on by then. i wana work in a pub, duno why, not any pub, not a big pub, i'd love to work the fox n hound by jill's - it's small n friendly, i think thats what attracks me to bein a barmaid - every1 thinks its somit to look down on but what's so bad bein surrounded by people in a friendly (if smoky :s) atmosphere? mayb im naive... also hav a job lined up with jill i hope :) i love the sound of what she plans to do and she says she'll employ me :) ur pretty much self-employed to be honest so it should happen n im into herbal homeopathic stuff so sounds good for me. after that id love to work in italy or canada. i cant speak italian so that leaves canada lol. although i don't have enough points for a visa :( i hav a friend who's gona help me as he's canadian (thats gota help!) and if i end up workin for a whole year before i go then that shld give me more points, plus im gona try learn french alongside my psychology degree, i wana speak french newas but now i hav a goal for it and will give me more points the better at it i am. the biggest problem is probably death - i.e. getting in a plane... ive been thinkin bout takin a flight course to help me feel more prepared for flying, but i don't see how im gona erase the knowledge that it could crash - and if it does it's the worst possible thing to be in that crashes. i dont wana die. if i do, i dont wana die like that. but then more than not wanting to die, i wana live, i know wot i mean... which brings me onto the fact that i realy should start jogging again. i wana b able to do the 10mile fun run next year to raise money for something that keeps catching my eye, i seem to read about it in magazines n papers all the time, n things through the door, it breaks my heart, if there's nethin i can do i wana do it. not because im such a great person just because ive seen the effects.... newas...will b a new years resolution lol im pathetic camp america should be cool too, wish it was this summer though as im gona b bored outa my brain n probs comit suicide for somit fun to do...talkin of which my mum thinks im on drugs, seriously do i come across as that abnormal n screwed? i guess we just have different views on what's normal, what emotions n behaviour are acceptable, whats good for us etc. o well arrivedechi x      \n",
      "Accented chars removed ::                   i can't wait for things to get moving, i want out of here. im lookin forward to uni although it means another 3 years in england. it should be so much fun from my experiences of it so far and my brother's experiences. after uni though it will be another year i guess before i can move, as i'll need to work for 'bout that long to get some money. will be quite lonely i imagine as every1 will have moved on by then. i wana work in a pub, duno why, not any pub, not a big pub, i'd love to work the fox n hound by jill's - it's small n friendly, i think thats what attracks me to bein a barmaid - every1 thinks its somit to look down on but what's so bad bein surrounded by people in a friendly (if smoky :s) atmosphere? mayb im naive... also hav a job lined up with jill i hope :) i love the sound of what she plans to do and she says she'll employ me :) ur pretty much self-employed to be honest so it should happen n im into herbal homeopathic stuff so sounds good for me. after that id love to work in italy or canada. i cant speak italian so that leaves canada lol. although i don't have enough points for a visa :( i hav a friend who's gona help me as he's canadian (thats gota help!) and if i end up workin for a whole year before i go then that shld give me more points, plus im gona try learn french alongside my psychology degree, i wana speak french newas but now i hav a goal for it and will give me more points the better at it i am. the biggest problem is probably death - i.e. getting in a plane... ive been thinkin bout takin a flight course to help me feel more prepared for flying, but i don't see how im gona erase the knowledge that it could crash - and if it does it's the worst possible thing to be in that crashes. i dont wana die. if i do, i dont wana die like that. but then more than not wanting to die, i wana live, i know wot i mean... which brings me onto the fact that i realy should start jogging again. i wana b able to do the 10mile fun run next year to raise money for something that keeps catching my eye, i seem to read about it in magazines n papers all the time, n things through the door, it breaks my heart, if there's nethin i can do i wana do it. not because im such a great person just because ive seen the effects.... newas...will b a new years resolution lol im pathetic camp america should be cool too, wish it was this summer though as im gona b bored outa my brain n probs comit suicide for somit fun to do...talkin of which my mum thinks im on drugs, seriously do i come across as that abnormal n screwed? i guess we just have different views on what's normal, what emotions n behaviour are acceptable, whats good for us etc. o well arrivedechi x      \n",
      "Upon removing Special chars ::                  i cant wait for things to get moving i want out of here im lookin forward to uni although it means another 3 years in england it should be so much fun from my experiences of it so far and my brothers experiences after uni though it will be another year i guess before i can move as ill need to work for bout that long to get some money will be quite lonely i imagine as every1 will have moved on by then i wana work in a pub duno why not any pub not a big pub id love to work the fox n hound by jills  its small n friendly i think thats what attracks me to bein a barmaid  every1 thinks its somit to look down on but whats so bad bein surrounded by people in a friendly if smoky s atmosphere mayb im naive also hav a job lined up with jill i hope  i love the sound of what she plans to do and she says shell employ me  ur pretty much selfemployed to be honest so it should happen n im into herbal homeopathic stuff so sounds good for me after that id love to work in italy or canada i cant speak italian so that leaves canada lol although i dont have enough points for a visa  i hav a friend whos gona help me as hes canadian thats gota help and if i end up workin for a whole year before i go then that shld give me more points plus im gona try learn french alongside my psychology degree i wana speak french newas but now i hav a goal for it and will give me more points the better at it i am the biggest problem is probably death  ie getting in a plane ive been thinkin bout takin a flight course to help me feel more prepared for flying but i dont see how im gona erase the knowledge that it could crash  and if it does its the worst possible thing to be in that crashes i dont wana die if i do i dont wana die like that but then more than not wanting to die i wana live i know wot i mean which brings me onto the fact that i realy should start jogging again i wana b able to do the 10mile fun run next year to raise money for something that keeps catching my eye i seem to read about it in magazines n papers all the time n things through the door it breaks my heart if theres nethin i can do i wana do it not because im such a great person just because ive seen the effects newaswill b a new years resolution lol im pathetic camp america should be cool too wish it was this summer though as im gona b bored outa my brain n probs comit suicide for somit fun to dotalkin of which my mum thinks im on drugs seriously do i come across as that abnormal n screwed i guess we just have different views on whats normal what emotions n behaviour are acceptable whats good for us etc o well arrivedechi x      \n",
      "Upon removing emojis ::            These are the team members   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail          \n",
      "Upon removing stopwords ::                   can't wait things get moving, want here. im lookin forward uni although means another 3 years england. much fun experiences far brother's experiences. uni though another year guess move, i'll need work 'bout long get money. quite lonely imagine every1 moved then. wana work pub, duno why, pub, big pub, i'd love work fox n hound jill's - small n friendly, think thats attracks bein barmaid - every1 thinks somit look what's bad bein surrounded people friendly (if smoky :s) atmosphere? mayb im naive... also hav job lined jill hope :) love sound plans says she'll employ :) ur pretty much self-employed honest happen n im herbal homeopathic stuff sounds good me. id love work italy canada. cant speak italian leaves canada lol. although enough points visa :( hav friend who's gona help he's canadian (thats gota help!) end workin whole year go shld give points, plus im gona try learn french alongside psychology degree, wana speak french newas hav goal give points better am. biggest problem probably death - i.e. getting plane... ive thinkin bout takin flight course help feel prepared flying, see im gona erase knowledge could crash - worst possible thing crashes. dont wana die. do, dont wana die like that. wanting die, wana live, know wot mean... brings onto fact realy start jogging again. wana b able 10mile fun run next year raise money something keeps catching eye, seem read magazines n papers time, n things door, breaks heart, there's nethin wana it. im great person ive seen effects.... newas...will b new years resolution lol im pathetic camp america cool too, wish summer though im gona b bored outa brain n probs comit suicide somit fun do...talkin mum thinks im drugs, seriously come across abnormal n screwed? guess different views what's normal, emotions n behaviour acceptable, whats good us etc. well arrivedechi x      \n",
      "Removing non english text ::  i can ' t wait for to get moving , i want out of here . forward to although it another 3 in . it should be so much fun from my of it so far and my brother ' s . after though it will be another year i guess before i can move , as i ' need to work for ' bout that long to get some money . will be quite lonely i imagine as every1 will have on by then . i work in a pub , why , not any pub , not a big pub , i ' d love to work the fox n hound by ' s - it ' s small n friendly , i think thats what me to a barmaid - every1 its to look down on but what ' s so bad surrounded by people in a friendly ( if smoky : s ) atmosphere ? naive ... also a job lined up with i hope :) i love the sound of what she to do and she she ' employ me :) ur pretty much self - employed to be honest so it should happen n into herbal homeopathic stuff so good for me . after that id love to work in or canada . i cant speak so that leaves canada . although i don ' t have enough for a visa :( i a friend who ' s help me as he ' s ( thats help !) and if i end up for a whole year before i go then that give me more , plus try learn alongside my psychology degree , i speak but now i a goal for it and will give me more the better at it i am . the biggest problem is probably death - i . e . getting in a plane ... been bout takin a flight course to help me feel more prepared for flying , but i don ' t see how erase the knowledge that it could crash - and if it does it ' s the worst possible thing to be in that . i dont die . if i do , i dont die like that . but then more than not wanting to die , i live , i know wot i mean ... which me onto the fact that i should start again . i b able to do the 10mile fun run next year to raise money for something that catching my eye , i seem to read about it in n all the time , n through the door , it my heart , if there ' s i can do i do it . not because such a great person just because seen the effects .... ... will b a new resolution pathetic camp should be cool too , wish it was this summer though as b my brain n suicide for fun to do ... of which my mum on , seriously do i come across as that abnormal n screwed ? i guess we just have different on what ' s normal , what n behaviour are acceptable , whats good for us . o well x\n",
      "lemmatize_sent ::  i ca n't wait for thing to get move , i want out of here . im lookin forward to uni although it mean another 3 year in england . it should be so much fun from my experience of it so far and my brother 's experience . after uni though it will be another year i guess before i can move , a i 'll need to work for 'bout that long to get some money . will be quite lonely i imagine a every1 will have move on by then . i wana work in a pub , duno why , not any pub , not a big pub , i 'd love to work the fox n hound by jill 's - it 's small n friendly , i think thats what attracks me to bein a barmaid - every1 think it somit to look down on but what 's so bad bein surround by people in a friendly ( if smoky : s ) atmosphere ? mayb im naive ... also hav a job line up with jill i hope : ) i love the sound of what she plan to do and she say she 'll employ me : ) ur pretty much self-employed to be honest so it should happen n im into herbal homeopathic stuff so sounds good for me . after that id love to work in italy or canada . i cant speak italian so that leave canada lol . although i do n't have enough point for a visa : ( i hav a friend who 's gona help me a he 's canadian ( thats gota help ! ) and if i end up workin for a whole year before i go then that shld give me more point , plus im gona try learn french alongside my psychology degree , i wana speak french newas but now i hav a goal for it and will give me more point the good at it i be . the big problem be probably death - i.e . get in a plane ... ive be thinkin bout takin a flight course to help me feel more prepared for fly , but i do n't see how im gona erase the knowledge that it could crash - and if it do it 's the bad possible thing to be in that crash . i dont wana die . if i do , i dont wana die like that . but then more than not want to die , i wana live , i know wot i mean ... which bring me onto the fact that i realy should start jog again . i wana b able to do the 10mile fun run next year to raise money for something that keep catch my eye , i seem to read about it in magazine n paper all the time , n thing through the door , it break my heart , if there 's nethin i can do i wana do it . not because im such a great person just because ive see the effect ... . newas ... will b a new year resolution lol im pathetic camp america should be cool too , wish it be this summer though a im gona b bore outa my brain n probs comit suicide for somit fun to do ... talkin of which my mum think im on drug , seriously do i come across a that abnormal n screw ? i guess we just have different view on what 's normal , what emotions n behaviour be acceptable , whats good for u etc . o well arrivedechi x\n",
      "lemmed :  i ca n't wait for thing to get move , i want out of here . im lookin forward to uni although it mean another 3 year in england . it should be so much fun from my experience of it so far and my brother 's experience . after uni though it will be another year i guess before i can move , a i 'll need to work for 'bout that long to get some money . will be quite lonely i imagine a every1 will have move on by then . i wana work in a pub , duno why , not any pub , not a big pub , i 'd love to work the fox n hound by jill 's - it 's small n friendly , i think thats what attracks me to bein a barmaid - every1 think it somit to look down on but what 's so bad bein surround by people in a friendly ( if smoky : s ) atmosphere ? mayb im naive ... also hav a job line up with jill i hope : ) i love the sound of what she plan to do and she say she 'll employ me : ) ur pretty much self-employed to be honest so it should happen n im into herbal homeopathic stuff so sounds good for me . after that id love to work in italy or canada . i cant speak italian so that leave canada lol . although i do n't have enough point for a visa : ( i hav a friend who 's gona help me a he 's canadian ( thats gota help ! ) and if i end up workin for a whole year before i go then that shld give me more point , plus im gona try learn french alongside my psychology degree , i wana speak french newas but now i hav a goal for it and will give me more point the good at it i be . the big problem be probably death - i.e . get in a plane ... ive be thinkin bout takin a flight course to help me feel more prepared for fly , but i do n't see how im gona erase the knowledge that it could crash - and if it do it 's the bad possible thing to be in that crash . i dont wana die . if i do , i dont wana die like that . but then more than not want to die , i wana live , i know wot i mean ... which bring me onto the fact that i realy should start jog again . i wana b able to do the 10mile fun run next year to raise money for something that keep catch my eye , i seem to read about it in magazine n paper all the time , n thing through the door , it break my heart , if there 's nethin i can do i wana do it . not because im such a great person just because ive see the effect ... . newas ... will b a new year resolution lol im pathetic camp america should be cool too , wish it be this summer though a im gona b bore outa my brain n probs comit suicide for somit fun to do ... talkin of which my mum think im on drug , seriously do i come across a that abnormal n screw ? i guess we just have different view on what 's normal , what emotions n behaviour be acceptable , whats good for u etc . o well arrivedechi x\n",
      "time: 819 ms (started: 2021-10-31 11:07:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ilocat = 100\n",
    "print(\"Original Text :: \" , blog_df.text[ilocat])\n",
    "print(\"Accented chars removed :: \", CleanUpData.remove_accented_chars(blog_df.text[ilocat]))\n",
    "print(\"Upon removing Special chars ::\", CleanUpData.remove_special_characters(blog_df.text[ilocat]))\n",
    "print(\"Upon removing emojis ::\", CleanUpData.remove_emojis(blog_df.text[ilocat]))\n",
    "print(\"Upon removing stopwords ::\", CleanUpData.remove_stop_words(blog_df.text[ilocat]))\n",
    "print(\"Removing non english text :: \", CleanUpData.remove_non_english_words(blog_df.text[ilocat]))\n",
    "print(\"lemmatize_sent :: \" , CleanUpData.lemmatize_sent(blog_df.text[ilocat]))\n",
    "print(\"lemmed : \" , CleanUpData.lemmatize_sent(blog_df.text[ilocat]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141cae",
   "metadata": {
    "id": "b72bQ7zRJx6I"
   },
   "source": [
    "    Below function bind all the function used for cleaning text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefe506",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Px_bA5yZXZYt",
    "outputId": "786d3560-f57f-4cdf-acb0-f51febb053e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.71 ms (started: 2021-10-31 11:07:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def text_cleaner(inputDataFrame):\n",
    "    inputDataFrame['text'] = inputDataFrame.text.apply(CleanUpData.remove_special_characters)\n",
    "    inputDataFrame['text'] = inputDataFrame.text.apply(CleanUpData.remove_accented_chars)\n",
    "    inputDataFrame['text'] = inputDataFrame.text.apply(CleanUpData.remove_stop_words)\n",
    "    inputDataFrame['text'] = inputDataFrame.text.apply(CleanUpData.remove_non_english_words)\n",
    "    inputDataFrame['text'] = inputDataFrame.text.apply(CleanUpData.lemmatize_sent)\n",
    "    inputDataFrame['text'] = inputDataFrame.text.apply(CleanUpData.clean_text)\n",
    "    return inputDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bb10a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyNrAncC47y1",
    "outputId": "4d24b96f-bb5d-4622-c171-d9e72ba56d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40min 14s (started: 2021-10-31 11:07:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df['Cleaned_text'] = text_cleaner(blog_df['text'].to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bd171",
   "metadata": {
    "id": "G5Xi3AyEL4_z"
   },
   "source": [
    "  Label Encoding on the individual labels which will be used for tfidf vecorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480d6a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "ibw6618nYWNB",
    "outputId": "a8b1ba16-9fcf-4d3a-8d6e-0806cce71f2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: User-defined function verification is still under development in Modin. The function provided is not verified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>gender_le</th>\n",
       "      <th>topic_le</th>\n",
       "      <th>sign_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>find 100 45 now wait untill team leader</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>these team van mail mail mail</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>in het van how build from subject how to build...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>test test</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>thanks i capture i show cool link pop audio vi...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "      <td>dear i could write really bitter diatribe dise...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "      <td>dear i second yeast infection past two straigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "      <td>dear your bald good luck</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "      <td>dear just clarify i leave house why piss floor...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "      <td>hey you might already know my weird al i get t...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681284 rows x 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id gender  age  ... gender_le topic_le sign_le\n",
       "0       2059027   male   15  ...         1       34       5\n",
       "1       2059027   male   15  ...         1       34       5\n",
       "2       2059027   male   15  ...         1       34       5\n",
       "3       2059027   male   15  ...         1       34       5\n",
       "4       3581210   male   33  ...         1       20       0\n",
       "...         ...    ...  ...  ...       ...      ...     ...\n",
       "681279  1713845   male   23  ...         1       34      10\n",
       "681280  1713845   male   23  ...         1       34      10\n",
       "681281  1713845   male   23  ...         1       34      10\n",
       "681282  1713845   male   23  ...         1       34      10\n",
       "681283  1713845   male   23  ...         1       34      10\n",
       "\n",
       "[681284 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34.7 s (started: 2021-10-31 11:48:01 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "# df[['gender', 'topic', 'sign']] = df[['gender', 'topic', 'sign']].apply(le.fit_transform)\n",
    "blog_df['gender_le'] = blog_df[['gender']].apply(le.fit_transform)\n",
    "blog_df['topic_le'] = blog_df[['topic']].apply(le.fit_transform)\n",
    "blog_df['sign_le'] = blog_df[['sign']].apply(le.fit_transform)\n",
    "\n",
    "categories = ['gender_le', 'sign_le' , 'topic_le',  'age']\n",
    "blog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2be22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a94J45jZK7Ug",
    "outputId": "2f22d77e-1ce0-4498-a827-3c34d3e2165c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.9 ms (started: 2021-10-31 11:48:36 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Below piece of code is replaced by using Modin \n",
    "# from more_itertools import sliced\n",
    "# CHUNK_SIZE = 100\n",
    "\n",
    "# index_slices = sliced(range(len(blog_df)), CHUNK_SIZE)\n",
    "\n",
    "# listOdDf = []\n",
    "# for index_slice in index_slices:\n",
    "#   chunk = blog_df.iloc[index_slice]\n",
    "#   listOdDf.append(chunk)\n",
    "\n",
    "# with Pool(processes=6) as pool:\n",
    "#   result = pool.map(review_cleaner, listOdDf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7759c4",
   "metadata": {
    "id": "gtNR8qFdNOGt"
   },
   "source": [
    "    Check few records in dataframe, This manual checking would help to understand the data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83e654",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKD354n-NYcn",
    "outputId": "44581a1d-e93a-4710-909d-23091a81c2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Last night was pretty fun...mostly because of the company I kept.  I recently met a couple of finance-types here in Yeouido (which isn't too hard to do, as it's referred to as Korea's Wall Street) who spoke pretty good English (which is a rarity here not only in Yeouido but everywhere in Korea).  They had studied outside Korea and deal with international business...but still my brutal Canadian accent made it pretty tough for them to figure out what I was saying sometimes.  There was one time that their accent got in the way, though.  When we went to the restaurant the guy (Junseok, the gal is named Hye-Kyung) asked: 'Do you like deok?'  I wrote it just as I heard it.  I thought he meant dog (they eat that here) so I called his bluff and said, 'Sure, let's go! What kind of dog?' 'Oh no, deok, deok!' 'Ya, dog?' 'No, deok,' he said again. Then I figured out that he meant 'duck' and said, 'Oh, &#50724;&#47532; (oh-ri), duck! Not &#44060; (gay), dog! Why didn't you just speak Korean?  I know &#50724;&#47532; and &#44060;!'  The food was great, then we went to the obligatory 이차 (ee-cha, thanks Hye-Kyung for the correction) or second round.  Koreans can never just go to one place to eat and drink.  Usually we will wander the streets and go out to three, four or five places. A couple of weeks ago in Hongdae (university bar district here) we went to 4 places: the &#49328;&#45209;&#51648; (san-nak-ji, living octopus) restaurant, Old Rock (cool bar), a &#45432;&#47000;&#48169; (noraebang, Korean word for karaoke) and finally clubnb (or noise basement) until the wee hours of the morning.  (Personally I prefer the Kangnam version of clubnb, but since we were in Hongdae we went to that one.)  The coolest thing here about bar-hopping/pub-crawling is there is almost never a lineup and very rarely a cover (just in the clubs, never in bars).  I think this is because people are always moving.  In Canada if you get in a bar you never, never leave until you go home...which means those who want to get in have to lineup.  Also, if a Korean is asked to wait (for anything, especially after a few drinks) they will just balk and leave...and no bar-owner would like that.  Maybe that's why Koreans in general are moving around more and Canadians are so sedate (relatively...if you've lived in both places you know what I mean).   Update:  looks like everyone wants to be on my blog...for some reason.  Here are the pics of my gracious hosts of the evening.   urlLink    Junseok, who works in International Business and has an MBA...he's trying to come up with a fitting Western name for himself, if you have one to suggest just leave a comment, please.   urlLink    Hae-Kyung, who works with him.  She too has an MBA (and from my wife's alma mater of Ewha Women's University, no less).  Hae-Kyung is really good at English and is quite bright...and single (men, take note). She thinks her face looks like the moon, or 달덩이 (Daldeong-ee) as they say here, I guess so...         \n",
      "last night pretty company i keep i recently meet couple hard wall street speak pretty good rarity everywhere they study outside deal international still brutal accent make pretty tough figure i say sometimes there one time accent get way though when go restaurant guy gal do like i write i i think meant dog eat i bluff say sure go what kind dog oh ya dog no say then i figure meant duck say oh 5072447532 duck not 44060 gay dog why didnt speak i know 5072447532 44060 the food great go obligatory thanks correction second round never go one place eat drink usually wander street go three four five a couple ago university bar district go 4 493284520951648 living octopus restaurant old rock cool bar 454324700048169 word karaoke finally noise basement wee morning personally i prefer version since go one the thing almost never rarely cover never i think people always move in canada get bar never never leave go want get also wait anything especially balk would like maybe thats general move around sedate youve live know i mean update like everyone reason here gracious even works international business try come fitting western name one suggest leave comment please work she alma mater university less really good quite single men take note she face like moon say i guess\n",
      "time: 347 ms (started: 2021-10-31 11:48:36 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(blog_df.text[12])\n",
    "print(blog_df.Cleaned_text[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e58fc",
   "metadata": {
    "id": "mR2RIn7KAYa9"
   },
   "source": [
    "### Target/label merger and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58d0fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlESRMFqAY2T",
    "outputId": "9f404b8f-dbf1-4c8e-dbd5-fa595dba2eec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: User-defined function verification is still under development in Modin. The function provided is not verified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.9 s (started: 2021-10-31 11:48:36 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df['label_four_column'] = blog_df.apply(lambda col : [col['gender'],col['age'],col['topic'],col['sign']], axis=1)\n",
    "blog_df['label_three_column'] = blog_df.apply(lambda col : [col['gender'],col['topic'],col['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bad67d",
   "metadata": {
    "id": "w3L6eNCRAg46"
   },
   "source": [
    "### Train and test split\n",
    "\n",
    "  There will be 2 types of approachs\n",
    "\n",
    "  Approach #1: Application of algorithm on text VS single label [gender, age, topic, sign] separately. \n",
    "              In this approach, there will be 2 types of vecotrization technique tried - TFIDF and count vectorizer.\n",
    "\n",
    "  Approach #2: Application of algorithm on text VS merged labels.\n",
    "\n",
    "  Appropriate marking are done for these approaches in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dff626",
   "metadata": {
    "id": "6EUbBgEUHF5o"
   },
   "source": [
    "  Approach #1: Application of algorithm on text VS single label [gender, age, topic, sign] separately. The code for same are in cells below. At first we shall look into count vectorizer technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f19af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLK3G647AEYZ",
    "outputId": "862e84be-5b35-4d9e-ebdd-d2a759100f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510963,)\n",
      "(510963,)\n",
      "(170321,)\n",
      "(170321,)\n",
      "time: 17.9 s (started: 2021-10-31 11:49:05 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split X and y into training and testing sets\n",
    "blog_topic_train, blog_topic_test, y_topic_train, y_topic_test = train_test_split(blog_df.Cleaned_text, blog_df.topic, random_state=2)\n",
    "\n",
    "#Traing data\n",
    "print(blog_topic_train.shape)\n",
    "print(y_topic_train.shape)\n",
    "\n",
    "#Test Data\n",
    "print(blog_topic_test.shape)\n",
    "print(y_topic_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1219388",
   "metadata": {
    "id": "3ZdA51nkBF_3"
   },
   "source": [
    "### Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30f7ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmaWsxXQNy0F",
    "outputId": "632d70b4-110c-4c8d-b01d-9556de4fca96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.83 ms (started: 2021-10-31 11:49:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#we can restrict the number of features using below method\n",
    "# cvect = CountVectorizer(min_df=2, max_df=0.5, max_features=300)\n",
    "\n",
    "#CountVectorizer (with the default parameters)\n",
    "cvect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e70bb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIJqUBtYOG_e",
    "outputId": "0b94586f-7b0a-4a2d-b762-a64cb06320c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 49.4 s (started: 2021-10-31 11:49:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#CountVectorize the blog data\n",
    "cvect.fit(blog_topic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56a13a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CzjFKy9GOMGm",
    "outputId": "18efccf1-e261-42b1-94e3-1bbd2b7a4aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160634\n",
      "time: 1.19 ms (started: 2021-10-31 11:50:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Check the vocablury size\n",
    "print(len(cvect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aac62e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhRyphT2OMga",
    "outputId": "a33cdfb3-1dc1-45b6-e9e8-850604fd5cd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thats': 147555,\n",
       " 'sure': 145340,\n",
       " 'come': 79613,\n",
       " 'place': 127347,\n",
       " 'read': 133166,\n",
       " 'let': 112515,\n",
       " 'introduce': 108122,\n",
       " 'first': 91849,\n",
       " 'year': 159771,\n",
       " '2000': 23215,\n",
       " 'computer': 79973,\n",
       " 'science': 137813,\n",
       " 'graduate': 95726,\n",
       " 'fast': 90967,\n",
       " 'institute': 107649,\n",
       " 'topper': 149294,\n",
       " 'share': 139424,\n",
       " '378': 37269,\n",
       " 'two': 150784,\n",
       " 'batch': 72096,\n",
       " 'after': 66994,\n",
       " 'graduation': 95729,\n",
       " 'one': 122851,\n",
       " 'prestigious': 130460,\n",
       " 'clear': 78832,\n",
       " 'exam': 89662,\n",
       " '91': 61285,\n",
       " 'select': 138543,\n",
       " 'application': 69239,\n",
       " 'server': 139003,\n",
       " 'commerce': 79716,\n",
       " 'suite': 144916,\n",
       " 'training': 149640,\n",
       " 'conduct': 80132,\n",
       " 'train': 149631,\n",
       " 'back': 71349,\n",
       " 'company': 79809,\n",
       " 'day': 83236,\n",
       " 'later': 111940,\n",
       " '2001': 23356,\n",
       " 'hire': 98468,\n",
       " 'write': 158579,\n",
       " 'transaction': 149683,\n",
       " 'engine': 88611,\n",
       " 'specialize': 142432,\n",
       " 'banking': 71806,\n",
       " 'domain': 86057,\n",
       " 'upon': 154092,\n",
       " 'completion': 79891,\n",
       " 'project': 130917,\n",
       " 'give': 94970,\n",
       " '50': 44856,\n",
       " 'increment': 106812,\n",
       " 'pay': 125593,\n",
       " 'well': 157050,\n",
       " 'promotion': 130976,\n",
       " 'work': 158312,\n",
       " 'next': 120354,\n",
       " 'half': 97013,\n",
       " 'various': 154898,\n",
       " 'almost': 67789,\n",
       " 'always': 67952,\n",
       " 'set': 139047,\n",
       " 'follow': 92490,\n",
       " 'three': 148214,\n",
       " 'experience': 89969,\n",
       " 'try': 150341,\n",
       " 'move': 118394,\n",
       " 'abroad': 66083,\n",
       " 'high': 98315,\n",
       " 'education': 87791,\n",
       " 'what': 157245,\n",
       " 'ill': 105987,\n",
       " 'cover': 81356,\n",
       " 'behind': 72577,\n",
       " 'the': 147567,\n",
       " 'people': 125988,\n",
       " 'like': 112883,\n",
       " 'ie': 105829,\n",
       " 'want': 156435,\n",
       " 'create': 81683,\n",
       " 'difference': 84880,\n",
       " 'knowledge': 110941,\n",
       " 'spirit': 142682,\n",
       " 'path': 125457,\n",
       " 'base': 72012,\n",
       " 'if': 105848,\n",
       " 'believer': 72635,\n",
       " 'surely': 145344,\n",
       " 'benefit': 72746,\n",
       " 'series': 138963,\n",
       " 'relate': 134090,\n",
       " 'sorry': 142086,\n",
       " 'havent': 97514,\n",
       " 'much': 118699,\n",
       " 'probably': 130714,\n",
       " 'speak': 142405,\n",
       " 'panto': 125009,\n",
       " 'every': 89479,\n",
       " 'night': 120500,\n",
       " 'week': 156932,\n",
       " 'till': 148521,\n",
       " '11pm': 10386,\n",
       " 'time': 148555,\n",
       " 'get': 94748,\n",
       " 'home': 98755,\n",
       " 'so': 141544,\n",
       " 'bet': 72898,\n",
       " 'reason': 133283,\n",
       " 'actually': 66499,\n",
       " 'watch': 156624,\n",
       " 'last': 111861,\n",
       " 'scenery': 137674,\n",
       " 'hilarious': 98369,\n",
       " 'dame': 82917,\n",
       " 'brilliant': 74931,\n",
       " 'end': 88498,\n",
       " 'they': 147928,\n",
       " 'sing': 140373,\n",
       " 'song': 141943,\n",
       " 'cat': 77005,\n",
       " 'tune': 150529,\n",
       " 'robin': 135647,\n",
       " 'hood': 98905,\n",
       " 'different': 84883,\n",
       " 'say': 137454,\n",
       " 'right': 135240,\n",
       " 'wrong': 158614,\n",
       " 'music': 118963,\n",
       " 'really': 133237,\n",
       " 'funny': 93680,\n",
       " 'also': 67876,\n",
       " 'audience': 70449,\n",
       " 'sit': 140493,\n",
       " 'bloke': 73752,\n",
       " 'totally': 149410,\n",
       " 'stood': 143944,\n",
       " 'thew': 147924,\n",
       " 'everyone': 89523,\n",
       " 'even': 89422,\n",
       " 'laugh': 111994,\n",
       " 'usually': 154483,\n",
       " 'doesnt': 85960,\n",
       " 'theyre': 147939,\n",
       " 'suppose': 145301,\n",
       " 'other': 123435,\n",
       " 'usual': 154479,\n",
       " 'princess': 130623,\n",
       " 'turn': 150589,\n",
       " 'cue': 82167,\n",
       " 'generally': 94582,\n",
       " 'good': 95447,\n",
       " 'wail': 156284,\n",
       " 'make': 114974,\n",
       " 'new': 120287,\n",
       " 'rather': 132989,\n",
       " 'nice': 120427,\n",
       " 'party': 125317,\n",
       " 'weekend': 156954,\n",
       " 'cant': 76537,\n",
       " 'wait': 156307,\n",
       " 'hah': 96900,\n",
       " 'ha': 96805,\n",
       " 'and': 68397,\n",
       " 'ahem': 67284,\n",
       " 'are': 69492,\n",
       " 'dont': 86128,\n",
       " 'mind': 117153,\n",
       " '20': 23213,\n",
       " 'yell': 159845,\n",
       " 'from': 93418,\n",
       " 'hell': 97938,\n",
       " 'awful': 70806,\n",
       " 'today': 148940,\n",
       " 'where': 157332,\n",
       " 'begin': 72544,\n",
       " 'tell': 147066,\n",
       " 'think': 148021,\n",
       " 'cosmic': 81104,\n",
       " 'joke': 109585,\n",
       " 'butt': 75648,\n",
       " 'stupid': 144432,\n",
       " 'bitch': 73366,\n",
       " 'middle': 116923,\n",
       " 'road': 135603,\n",
       " 'past': 125395,\n",
       " 'driven': 86587,\n",
       " 'away': 70773,\n",
       " 'house': 99156,\n",
       " 'she': 139476,\n",
       " 'there': 147834,\n",
       " 'car': 76649,\n",
       " 'side': 140105,\n",
       " 'perfectly': 126109,\n",
       " 'gap': 94249,\n",
       " 'go': 95236,\n",
       " 'order': 123217,\n",
       " 'man': 115124,\n",
       " 'slap': 140843,\n",
       " 'bus': 75541,\n",
       " 'drive': 86581,\n",
       " 'this': 148072,\n",
       " 'incident': 106665,\n",
       " 'irritable': 108489,\n",
       " 'rest': 134724,\n",
       " 'something': 141896,\n",
       " 'small': 141156,\n",
       " 'bug': 75293,\n",
       " 'must': 119004,\n",
       " 'period': 126150,\n",
       " 'soon': 142005,\n",
       " 'customer': 82389,\n",
       " 'ignorant': 105905,\n",
       " 'wretch': 158554,\n",
       " 'we': 156791,\n",
       " 'keep': 110340,\n",
       " 'eye': 90242,\n",
       " 'west': 157157,\n",
       " 'patience': 125487,\n",
       " 'woman': 158136,\n",
       " 'horrible': 99005,\n",
       " 'mad': 114764,\n",
       " 'guy': 96508,\n",
       " 'manger': 115212,\n",
       " 'be': 72243,\n",
       " 'manager': 115161,\n",
       " 'feck': 91197,\n",
       " 'head': 97628,\n",
       " 'swing': 145694,\n",
       " 'round': 136011,\n",
       " 'point': 127825,\n",
       " 'view': 155311,\n",
       " 'leave': 112231,\n",
       " 'happy': 97253,\n",
       " 'chap': 77693,\n",
       " 'bum': 75391,\n",
       " 'ah': 67256,\n",
       " 'excitement': 89745,\n",
       " 'tomorrow': 149103,\n",
       " 'find': 91708,\n",
       " 'plan': 127398,\n",
       " 'weight': 157002,\n",
       " 'morning': 118178,\n",
       " 'lose': 113834,\n",
       " '72': 53809,\n",
       " '16': 16662,\n",
       " '12': 10551,\n",
       " 'stone': 143926,\n",
       " 'bit': 73362,\n",
       " 'less': 112498,\n",
       " 'still': 143806,\n",
       " 'pretty': 130507,\n",
       " 'know': 110913,\n",
       " 'wont': 158197,\n",
       " 'continue': 80605,\n",
       " 'peachy': 125708,\n",
       " 'slow': 141074,\n",
       " 'likely': 112961,\n",
       " 'remarkably': 134211,\n",
       " 'long': 113690,\n",
       " '125': 12069,\n",
       " '275': 30342,\n",
       " 'hope': 98949,\n",
       " 'calorie': 76332,\n",
       " 'far': 90891,\n",
       " 'nothing': 121579,\n",
       " '17020': 17802,\n",
       " 'leek': 112289,\n",
       " 'cauliflower': 77136,\n",
       " 'cucumber': 82160,\n",
       " 'garlic': 94295,\n",
       " 'red': 133609,\n",
       " 'grapefruit': 95818,\n",
       " '13616': 13737,\n",
       " 'tomato': 149082,\n",
       " 'zucchini': 160599,\n",
       " 'mandarin': 115179,\n",
       " '5987': 48057,\n",
       " '13474': 13609,\n",
       " 'celery': 77304,\n",
       " 'root': 135885,\n",
       " 'spinach': 142650,\n",
       " 'onion': 122904,\n",
       " '02': 803,\n",
       " 'cream': 81669,\n",
       " 'cheese': 77905,\n",
       " 'freeze': 93211,\n",
       " 'green': 95946,\n",
       " 'decent': 83644,\n",
       " 'aim': 67329,\n",
       " '200': 23214,\n",
       " 'problem': 130725,\n",
       " 'part': 125261,\n",
       " 'main': 114936,\n",
       " 'course': 81305,\n",
       " '7316': 54514,\n",
       " 'add': 66586,\n",
       " 'dessert': 84435,\n",
       " 'open': 123023,\n",
       " 'discussion': 85306,\n",
       " 'might': 116989,\n",
       " 'indulge': 107007,\n",
       " 'water': 156649,\n",
       " 'melon': 116359,\n",
       " 'choose': 78246,\n",
       " 'serve': 139002,\n",
       " 'size': 140540,\n",
       " 'would': 158462,\n",
       " '400': 39491,\n",
       " 'weighed': 156998,\n",
       " 'peel': 125802,\n",
       " '6760': 51786,\n",
       " '14076': 14339,\n",
       " 'altogether': 67926,\n",
       " 'though': 148159,\n",
       " 'yummy': 160262,\n",
       " '650': 51249,\n",
       " 'extra': 90160,\n",
       " 'final': 91685,\n",
       " 'total': 149394,\n",
       " '14726': 14893,\n",
       " 'see': 138431,\n",
       " 'could': 81181,\n",
       " 'buy': 75697,\n",
       " '240': 28286,\n",
       " '7900': 56100,\n",
       " 'maybe': 115927,\n",
       " 'weigh': 156996,\n",
       " '66': 51552,\n",
       " 'huge': 105000,\n",
       " 'freezer': 93212,\n",
       " '100': 4126,\n",
       " 'bag': 71562,\n",
       " '4130': 40359,\n",
       " '12096': 10973,\n",
       " 'sound': 142144,\n",
       " 'confuse': 80247,\n",
       " 'someone': 141884,\n",
       " 'whenever': 157327,\n",
       " 'eat': 87439,\n",
       " 'drink': 86567,\n",
       " 'big': 73092,\n",
       " 'glass': 95029,\n",
       " 'table': 146236,\n",
       " 'prepare': 130308,\n",
       " 'food': 92526,\n",
       " 'possible': 128303,\n",
       " 'never': 120281,\n",
       " 'voluntarily': 155697,\n",
       " '7pm': 56657,\n",
       " 'front': 93430,\n",
       " 'structure': 144304,\n",
       " 'anyway': 69036,\n",
       " 'figure': 91603,\n",
       " 'math': 115749,\n",
       " '62193': 50202,\n",
       " 'midnight': 116943,\n",
       " '8885': 59877,\n",
       " 'per': 126034,\n",
       " 'damn': 82927,\n",
       " 'thing': 147981,\n",
       " 'nbsp200': 119774,\n",
       " 'twist': 150764,\n",
       " 'reverse': 134976,\n",
       " 'version': 155146,\n",
       " '2468': 28584,\n",
       " 'way': 156724,\n",
       " 'average': 70705,\n",
       " 'daily': 82873,\n",
       " 'intake': 107727,\n",
       " 'gulp': 96414,\n",
       " '11429': 9246,\n",
       " '3001500': 33609,\n",
       " '171': 17872,\n",
       " 'o_onbspat': 122162,\n",
       " 'moment': 117786,\n",
       " 'deal': 83491,\n",
       " 'mess': 116590,\n",
       " 'body': 74040,\n",
       " 'suddenly': 144836,\n",
       " '14286': 14525,\n",
       " 'nonexistent': 121057,\n",
       " 'metabolism': 116621,\n",
       " 'differently': 84890,\n",
       " 'consult': 80512,\n",
       " 'yesterday': 159918,\n",
       " 'goal': 95256,\n",
       " 'loss': 113842,\n",
       " 'tend': 147157,\n",
       " 'start': 143461,\n",
       " 'healthy': 97697,\n",
       " 'diet': 84865,\n",
       " 'constantly': 80467,\n",
       " 'accord': 66288,\n",
       " 'need': 120045,\n",
       " 'sense': 138795,\n",
       " 'world': 158373,\n",
       " 'trouble': 150211,\n",
       " 'maintain': 114944,\n",
       " 'vary': 154909,\n",
       " 'quite': 132293,\n",
       " 'depend': 84200,\n",
       " 'calculator': 76248,\n",
       " 'use': 154440,\n",
       " 'found': 92939,\n",
       " 'id': 105713,\n",
       " 'burn': 75497,\n",
       " '13058': 13169,\n",
       " 'bed': 72408,\n",
       " 'site': 140496,\n",
       " 'rely': 134192,\n",
       " '131200': 13305,\n",
       " '1300': 13062,\n",
       " 'consider': 80413,\n",
       " 'personally': 126307,\n",
       " 'obviously': 122336,\n",
       " 'nearly': 119982,\n",
       " 'handy': 97178,\n",
       " 'count': 81192,\n",
       " 'deficit': 83830,\n",
       " 'certain': 77447,\n",
       " 'take': 146358,\n",
       " '150': 15402,\n",
       " 'mean': 116101,\n",
       " '1150': 9501,\n",
       " 'rate': 132979,\n",
       " 'pound': 129715,\n",
       " '25': 28959,\n",
       " 'certainly': 77448,\n",
       " 'impossible': 106403,\n",
       " 'reach': 133148,\n",
       " 'look': 113746,\n",
       " 'length': 112436,\n",
       " 'post': 128308,\n",
       " 'return': 134902,\n",
       " 'result': 134771,\n",
       " 'ramble': 132818,\n",
       " 'occasional': 122345,\n",
       " 'reader': 133174,\n",
       " 'lady': 111554,\n",
       " 'muffin': 118756,\n",
       " 'love': 113919,\n",
       " 'o_o': 122157,\n",
       " 'up': 153975,\n",
       " 'dollar': 86033,\n",
       " 'now': 121668,\n",
       " 'here': 98076,\n",
       " 'my': 119084,\n",
       " 'dream': 86482,\n",
       " 'pot': 129642,\n",
       " '280': 30595,\n",
       " 'million': 117102,\n",
       " 'raise': 132780,\n",
       " 'hand': 97106,\n",
       " 'completely': 79885,\n",
       " 'sum': 144958,\n",
       " 'money': 117854,\n",
       " 'collection': 79446,\n",
       " 'around': 69663,\n",
       " 'office': 122513,\n",
       " 'breath': 74814,\n",
       " 'lucky': 114115,\n",
       " 'late': 111895,\n",
       " 'idea': 105738,\n",
       " 'purchase': 131684,\n",
       " 'waterfront': 156659,\n",
       " 'property': 131031,\n",
       " 'town': 149500,\n",
       " 'revamp': 134935,\n",
       " 'city': 78604,\n",
       " 'then': 147737,\n",
       " 'remove': 134268,\n",
       " 'toxic': 149521,\n",
       " 'since': 140346,\n",
       " 'ancient': 68389,\n",
       " 'local': 113507,\n",
       " 'emperor': 88368,\n",
       " 'tribute': 149992,\n",
       " 'build': 75315,\n",
       " 'western': 157164,\n",
       " 'early': 87326,\n",
       " 'century': 77410,\n",
       " 'ad': 66521,\n",
       " 'didnt': 84840,\n",
       " 'attempt': 70360,\n",
       " 'govern': 95594,\n",
       " 'area': 69499,\n",
       " '18th': 19876,\n",
       " 'fifty': 91577,\n",
       " 'ago': 67198,\n",
       " 'live': 113361,\n",
       " 'outnumber': 123621,\n",
       " 'link': 113127,\n",
       " 'rat': 132975,\n",
       " 'travel': 149849,\n",
       " 'not': 121538,\n",
       " 'orientation': 123285,\n",
       " 'fat': 90988,\n",
       " 'granny': 95799,\n",
       " 'phone': 126676,\n",
       " 'schedule': 137699,\n",
       " 'dare': 83047,\n",
       " 'screw': 138011,\n",
       " 'reserve': 134595,\n",
       " 'park': 125205,\n",
       " 'them': 147700,\n",
       " 'crave': 81572,\n",
       " 'via': 155246,\n",
       " 'feel': 91223,\n",
       " 'least': 112213,\n",
       " 'extend': 90105,\n",
       " 'spot': 142858,\n",
       " 'parking': 125215,\n",
       " 'locker': 113532,\n",
       " 'second': 138333,\n",
       " 'consecutive': 80384,\n",
       " 'complete': 79882,\n",
       " 'game': 94171,\n",
       " '132': 13375,\n",
       " 'romp': 135799,\n",
       " 'it': 108646,\n",
       " 'offense': 122498,\n",
       " 'alive': 67634,\n",
       " 'wish': 157948,\n",
       " '10': 4125,\n",
       " 'spread': 142889,\n",
       " 'some': 141856,\n",
       " 'ready': 133196,\n",
       " 'concede': 80003,\n",
       " 'central': 77385,\n",
       " 'talk': 146400,\n",
       " 'wild': 157690,\n",
       " 'card': 76713,\n",
       " 'shoot': 139767,\n",
       " 'anything': 69029,\n",
       " 'happen': 97227,\n",
       " 'plus': 127690,\n",
       " 'beat': 72337,\n",
       " 'knew': 110863,\n",
       " 'help': 97974,\n",
       " 'st': 143209,\n",
       " 'skid': 140668,\n",
       " 'law': 112051,\n",
       " 'regardless': 133885,\n",
       " 'elsewhere': 88188,\n",
       " 'win': 157755,\n",
       " 'no': 120679,\n",
       " 'close': 78985,\n",
       " 'run': 136370,\n",
       " 'men': 116414,\n",
       " 'third': 148057,\n",
       " 'little': 113333,\n",
       " 'league': 112175,\n",
       " 'form': 92783,\n",
       " 'immortal': 106211,\n",
       " 'harry': 97372,\n",
       " 'crossword': 81914,\n",
       " 'puzzle': 131805,\n",
       " 'addict': 66597,\n",
       " 'without': 158015,\n",
       " 'mother': 118278,\n",
       " 'book': 74194,\n",
       " 'movie': 118403,\n",
       " 'bad': 71515,\n",
       " 'yet': 159949,\n",
       " 'addiction': 66600,\n",
       " 'crack': 81473,\n",
       " 'except': 89701,\n",
       " 'difficult': 84894,\n",
       " 'free': 93161,\n",
       " 'doe': 85951,\n",
       " 'anyone': 69022,\n",
       " 'cake': 76214,\n",
       " 'garbage': 94266,\n",
       " 'badly': 71544,\n",
       " 'drawn': 86470,\n",
       " 'boy': 74557,\n",
       " 'smith': 141251,\n",
       " 'queen': 132152,\n",
       " 'her': 98044,\n",
       " 'space': 142288,\n",
       " 'holiday': 98717,\n",
       " 'jeff': 109252,\n",
       " 'gemma': 94547,\n",
       " 'air': 67346,\n",
       " 'flaming': 92033,\n",
       " 'phantom': 126560,\n",
       " 'planet': 127411,\n",
       " 'nick': 120448,\n",
       " 'drake': 86426,\n",
       " 'star': 143403,\n",
       " 'sam': 137074,\n",
       " 'imperial': 106309,\n",
       " 'teen': 146991,\n",
       " 'aptly': 69351,\n",
       " 'that': 147516,\n",
       " 'radio': 132654,\n",
       " 'list': 113256,\n",
       " 'sufficient': 144863,\n",
       " 'enough': 88703,\n",
       " 'comment': 79706,\n",
       " 'recommend': 133491,\n",
       " 'hint': 98436,\n",
       " 'top': 149240,\n",
       " 'when': 157319,\n",
       " 'rich': 135163,\n",
       " 'famous': 90829,\n",
       " 'school': 137750,\n",
       " 'matching': 115722,\n",
       " 'imagine': 106090,\n",
       " 'seven': 139085,\n",
       " 'extent': 90123,\n",
       " 'whole': 157526,\n",
       " 'group': 96148,\n",
       " 'felt': 91278,\n",
       " 'tired': 148762,\n",
       " 'baby': 71305,\n",
       " 'biology': 73255,\n",
       " 'test': 147334,\n",
       " 'swear': 145587,\n",
       " 'spend': 142532,\n",
       " 'damned': 82937,\n",
       " 'fell': 91261,\n",
       " 'asleep': 69930,\n",
       " 'section': 138378,\n",
       " 'study': 144366,\n",
       " 'guide': 96361,\n",
       " 'blah': 73507,\n",
       " 'class': 78730,\n",
       " 'favorite': 91086,\n",
       " 'fun': 93607,\n",
       " 'teacher': 146836,\n",
       " 'genius': 94627,\n",
       " 'answer': 68724,\n",
       " 'everything': 89530,\n",
       " 'pop': 128125,\n",
       " 'quiz': 132304,\n",
       " 'correctly': 81027,\n",
       " 'name': 119491,\n",
       " 'homer': 98802,\n",
       " 'deliver': 83997,\n",
       " 'telegram': 147033,\n",
       " 'once': 122841,\n",
       " 'entire': 88784,\n",
       " 'yes': 159885,\n",
       " 'ceramic': 77419,\n",
       " 'finish': 91749,\n",
       " 'glaze': 95047,\n",
       " 'algebra': 67578,\n",
       " 'pow': 129750,\n",
       " 'drama': 86428,\n",
       " 'nobody': 120783,\n",
       " 'history': 98505,\n",
       " 'went': 157128,\n",
       " 'nectar': 120039,\n",
       " 'afterschool': 67028,\n",
       " 'practice': 129910,\n",
       " 'ask': 69920,\n",
       " 'oh': 122594,\n",
       " 'bring': 74941,\n",
       " 'conversation': 80723,\n",
       " 'female': 91285,\n",
       " 'foot': 92555,\n",
       " 'pick': 126915,\n",
       " 'shot': 139834,\n",
       " 'attention': 70368,\n",
       " 'dead': 83451,\n",
       " 'double': 86222,\n",
       " 'seriously': 138975,\n",
       " 'em': 88210,\n",
       " 'anyways': 69048,\n",
       " 'all': 67652,\n",
       " 'already': 67858,\n",
       " 'in': 106495,\n",
       " 'actuality': 66495,\n",
       " '45': 42055,\n",
       " 'extremely': 90207,\n",
       " 'many': 115341,\n",
       " 'sign': 140194,\n",
       " 'seeing': 138465,\n",
       " 'loan': 113479,\n",
       " '2034': 24538,\n",
       " 'hover': 99225,\n",
       " 'moon': 118035,\n",
       " 'minimum': 117204,\n",
       " 'four': 92954,\n",
       " 'interest': 107852,\n",
       " 'but': 75631,\n",
       " 'concern': 80031,\n",
       " 'you': 160070,\n",
       " 'kind': 110623,\n",
       " 'celebration': 77293,\n",
       " 'faster': 90976,\n",
       " 'breakfast': 74784,\n",
       " 'recipe': 133436,\n",
       " 'wheat': 157290,\n",
       " 'tortilla': 149364,\n",
       " 'slice': 140951,\n",
       " 'low': 113963,\n",
       " 'turkey': 150576,\n",
       " 'egg': 87886,\n",
       " 'white': 157466,\n",
       " '14': 14230,\n",
       " 'cup': 82241,\n",
       " 'chop': 78252,\n",
       " 'yellow': 159849,\n",
       " 'pinch': 127112,\n",
       " 'spray': 142886,\n",
       " 'cooking': 80789,\n",
       " 'oil': 122639,\n",
       " 'non': 120857,\n",
       " 'stick': 143767,\n",
       " 'omelet': 122750,\n",
       " 'pan': 124912,\n",
       " 'over': 123749,\n",
       " 'medium': 116227,\n",
       " 'flame': 92022,\n",
       " 'heat': 97766,\n",
       " 'toss': 149386,\n",
       " 'cook': 80781,\n",
       " 'stir': 143856,\n",
       " 'continually': 80601,\n",
       " 'finally': 91696,\n",
       " 'allow': 67745,\n",
       " 'flip': 92194,\n",
       " 'mixture': 117547,\n",
       " 'pico': 126938,\n",
       " 'plain': 127386,\n",
       " 'real': 133204,\n",
       " 'basic': 72039,\n",
       " 'fresh': 93242,\n",
       " 'large': 111812,\n",
       " 'any': 68986,\n",
       " 'pepper': 126016,\n",
       " 'dry': 86691,\n",
       " 'whatever': 157276,\n",
       " 'le': 112135,\n",
       " 'spicy': 142593,\n",
       " 'palatable': 124831,\n",
       " 'salt': 137041,\n",
       " 'cut': 82396,\n",
       " 'spice': 142583,\n",
       " 'chart': 77771,\n",
       " 'for': 92592,\n",
       " 'killy': 110603,\n",
       " 'giant': 94827,\n",
       " 'potato': 129646,\n",
       " 'chip': 78130,\n",
       " 'boil': 74071,\n",
       " 'blender': 73615,\n",
       " 'skin': 140699,\n",
       " 'else': 88178,\n",
       " 'chunk': 78414,\n",
       " 'painful': 124783,\n",
       " 'theres': 147877,\n",
       " 'chemical': 77933,\n",
       " 'reaction': 133157,\n",
       " 'taste': 146658,\n",
       " 'put': 131786,\n",
       " 'blend': 73613,\n",
       " 'whirl': 157435,\n",
       " 'disintegrate': 85397,\n",
       " 'stop': 143960,\n",
       " 'blending': 73618,\n",
       " 'soupy': 142171,\n",
       " 'chunky': 78415,\n",
       " 'drown': 86643,\n",
       " 'enjoy': 88663,\n",
       " 'hey': 98225,\n",
       " 'amber': 68039,\n",
       " 'life': 112784,\n",
       " 'w00t': 155852,\n",
       " 'thanks': 147502,\n",
       " 'uber1337': 150982,\n",
       " 'hax0r': 97538,\n",
       " 'copy': 80887,\n",
       " 'perhaps': 126133,\n",
       " 'background': 71442,\n",
       " 'misery': 117362,\n",
       " 'sin': 140341,\n",
       " 'human': 105027,\n",
       " 'perfect': 126093,\n",
       " 'exist': 89877,\n",
       " 'within': 158006,\n",
       " 'reality': 133222,\n",
       " 'believe': 72632,\n",
       " 'power': 129757,\n",
       " 'dormant': 86180,\n",
       " 'learning': 112208,\n",
       " 'to': 148867,\n",
       " 'observe': 122289,\n",
       " 'observation': 122283,\n",
       " 'discrepancy': 85286,\n",
       " 'consistency': 80427,\n",
       " 'uniqueness': 152692,\n",
       " 'sinful': 140368,\n",
       " '2004': 23687,\n",
       " 'guess': 96341,\n",
       " 'nickname': 120468,\n",
       " 'wow': 158482,\n",
       " 'sinful_misery': 140370,\n",
       " 'yeah': 159741,\n",
       " 'awhile': 70811,\n",
       " 'summer': 144993,\n",
       " 'great': 95919,\n",
       " 'closer': 78999,\n",
       " 'bonding': 74154,\n",
       " 'lot': 113857,\n",
       " 'pity': 127280,\n",
       " 'intend': 107775,\n",
       " 'promise': 130966,\n",
       " 'wood': 158206,\n",
       " 'sport': 142836,\n",
       " 'along': 67828,\n",
       " 'nicely': 120440,\n",
       " 'ann': 68633,\n",
       " 'arbor': 69414,\n",
       " 'change': 77635,\n",
       " 'pace': 124657,\n",
       " 'switch': 145717,\n",
       " 'network': 120229,\n",
       " 'prove': 131203,\n",
       " 'valuable': 154812,\n",
       " 'transfer': 149710,\n",
       " 'production': 130803,\n",
       " '5kbps': 48567,\n",
       " '42kbps': 41022,\n",
       " 'service': 139013,\n",
       " 'public': 131480,\n",
       " 'receive': 133400,\n",
       " 'invitation': 108245,\n",
       " 'account': 66298,\n",
       " 'luckily': 114111,\n",
       " 'gig': 94860,\n",
       " '1000': 4127,\n",
       " 'delete': 83954,\n",
       " 'message': 116593,\n",
       " 'awesome': 70793,\n",
       " 'searching': 138221,\n",
       " 'of': 122461,\n",
       " 'search': 138212,\n",
       " 'youve': 160200,\n",
       " 'simple': 140312,\n",
       " 'effective': 87830,\n",
       " 'instead': 107635,\n",
       " 'filter': 91673,\n",
       " 'hopefully': 98954,\n",
       " 'improve': 106460,\n",
       " 'report': 134432,\n",
       " 'single': 140389,\n",
       " 'crap': 81537,\n",
       " 'mail': 114902,\n",
       " 'reply': 134427,\n",
       " 'basis': 72052,\n",
       " 'normal': 121468,\n",
       " 'messy': 116608,\n",
       " 'super': 145118,\n",
       " 'convenient': 80707,\n",
       " 'very': 155172,\n",
       " 'text': 147407,\n",
       " 'relevant': 134142,\n",
       " 'hardly': 97302,\n",
       " 'notice': 121588,\n",
       " 'interfere': 107869,\n",
       " 'banner': 71812,\n",
       " 'system': 145936,\n",
       " 'primary': 130595,\n",
       " 'example': 89676,\n",
       " 'supply': 145285,\n",
       " 'demand': 84030,\n",
       " 'sometimes': 141911,\n",
       " 'invite': 108247,\n",
       " 'at': 70173,\n",
       " 'werent': 157146,\n",
       " 'pas': 125333,\n",
       " 'sell': 138574,\n",
       " '80': 56911,\n",
       " 'piece': 126972,\n",
       " 'rid': 135193,\n",
       " 'dime': 84977,\n",
       " 'rip': 135338,\n",
       " 'recently': 133407,\n",
       " 'policy': 127905,\n",
       " 'trade': 149595,\n",
       " 'profit': 130853,\n",
       " 'although': 67917,\n",
       " 'another': 68711,\n",
       " 'boring': 74356,\n",
       " 'news': 120313,\n",
       " 'article': 69782,\n",
       " 'decide': 83656,\n",
       " 'just': 109915,\n",
       " 'tonyr1988gmailcom': 149175,\n",
       " 'send': 138761,\n",
       " 'address': 66609,\n",
       " 'cool': 80796,\n",
       " 'frost': 93448,\n",
       " 'ash': 69895,\n",
       " 'insanity': 107495,\n",
       " 'eh': 87927,\n",
       " 'depress': 84249,\n",
       " 'ortho': 123338,\n",
       " 'surgery': 145367,\n",
       " 'brace': 74620,\n",
       " 'month': 117995,\n",
       " '27th': 30549,\n",
       " 'drove': 86640,\n",
       " 'matter': 115830,\n",
       " 'dad': 82824,\n",
       " 'beetle': 72503,\n",
       " 'ugh': 151018,\n",
       " 'old': 122685,\n",
       " 'care': 76747,\n",
       " 'image': 106067,\n",
       " '40something': 40179,\n",
       " 'agent': 67142,\n",
       " 'plane': 127407,\n",
       " 'olive': 122727,\n",
       " 'garden': 94272,\n",
       " 'lunch': 114198,\n",
       " 'target': 146587,\n",
       " 'navy': 119711,\n",
       " 'do': 85857,\n",
       " 'tonight': 149152,\n",
       " 'mall': 115075,\n",
       " 'may': 115903,\n",
       " 'ton': 149121,\n",
       " 'best': 72875,\n",
       " 'chronological': 78360,\n",
       " 'stuff': 144377,\n",
       " 'rehearsal': 133981,\n",
       " 'smooth': 141292,\n",
       " 'dinner': 85031,\n",
       " 'minute': 117248,\n",
       " 'somewhat': 141915,\n",
       " '3am': 38018,\n",
       " 'kindergarten': 110625,\n",
       " '19': 19953,\n",
       " 'loose': 113776,\n",
       " 'control': 80675,\n",
       " 'bladder': 73495,\n",
       " 'wake': 156336,\n",
       " 'scratch': 137964,\n",
       " 'lost': 113846,\n",
       " 'suitcase': 144915,\n",
       " 'mine': 117169,\n",
       " 'depressed': 84251,\n",
       " 'sometime': 141909,\n",
       " 'sleep': 140908,\n",
       " 'upset': 154122,\n",
       " 'fall': 90774,\n",
       " 'eventually': 89453,\n",
       " 'downstairs': 86327,\n",
       " 'surprise': 145385,\n",
       " '5ambut': 48158,\n",
       " 'amazingly': 68027,\n",
       " 'salon': 137033,\n",
       " 'hair': 96952,\n",
       " 'ya': 159607,\n",
       " 'wed': 156892,\n",
       " 'ceremony': 77437,\n",
       " 'fan': 90832,\n",
       " 'cam': 76356,\n",
       " 'amy': 68243,\n",
       " 'twice': 150727,\n",
       " 'communion': 79777,\n",
       " 'step': 143677,\n",
       " 'father': 91020,\n",
       " 'lovely': 113940,\n",
       " 'lim': 113023,\n",
       " 'however': 99240,\n",
       " 'handle': 97144,\n",
       " 'humor': 105084,\n",
       " 'reception': 133414,\n",
       " 'lake': 111621,\n",
       " 'heaven': 97784,\n",
       " 'earth': 87376,\n",
       " 'girl': 94930,\n",
       " 'cute': 82402,\n",
       " 'together': 149006,\n",
       " 'bedroom': 72451,\n",
       " 'play': 127487,\n",
       " 'room': 135835,\n",
       " 'aunt': 70528,\n",
       " 'show': 139873,\n",
       " 'hang': 97180,\n",
       " 'laid': 111609,\n",
       " 'sun': 145036,\n",
       " 'beach': 72267,\n",
       " 'brother': 75077,\n",
       " 'picnic': 126937,\n",
       " 'tutti': 150656,\n",
       " 'warehouse': 156484,\n",
       " '96': 63306,\n",
       " 'short': 139805,\n",
       " 'forever': 92722,\n",
       " 'blind': 73641,\n",
       " 'clearer': 78836,\n",
       " 'present': 130378,\n",
       " 'son': 141934,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.6 ms (started: 2021-10-31 11:50:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#What is there in the vocabulary\n",
    "cvect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30dd228",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tlVHVRjOPZQ",
    "outputId": "6a0c8b71-bfa5-43fd-cf08-a795708e8ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.8 s (started: 2021-10-31 11:50:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Convert Training SMS messages into Count Vectors\n",
    "X_train_ct = cvect.transform(blog_topic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c82259",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gQTE2AXOSQy",
    "outputId": "4caf5753-21c9-4c5b-88b3-47f28ab86a8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510963, 160634)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.35 ms (started: 2021-10-31 11:51:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Size of Document Term Matrix\n",
    "X_train_ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b424a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz9hk5psOe6S",
    "outputId": "b8147f1c-4bdf-4023-e81c-b298c8056cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.6 s (started: 2021-10-31 11:51:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "X_test_ct = cvect.transform(blog_topic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2ca82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "nKkuBST4KpWM",
    "outputId": "b085e2f3-7085-4835-fc72-c7a525b49f63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"             So I've been in Vancouver a few days now...in Coquitlam, actually.  It's really an interesting place; I used to think it was full of Chinese people (not that there's anything wrong with that, but Vancouver's #1 mother tongue is Mandarin/Cantonese, so you'd assume there'd be tons here).  Our area is up on a hill in a little bit of paradise, actually.  It has started to remind me of Newport in that show  urlLink The O.C.  (O.C. means Orange County).  Well, it isn't full of million dollar homes (but there are a few) but the topography is similar (hills, lots of parks, but no beach) and it's really, really white here.  I think the only Koreans I've seen have been family and Ensign Harry Kim on Star Trek: Voyager (ya, still have jetlag...watching anything that hits the screen here).  On that note, I think I'm having T.V. overload.  Well, with the kids I don't get to see too much of it, but when I do I'm boggled by the 60+ stations (and that's not even satellite!) and all, save one, of them are in ENGLISH!  Wow!  In Seoul I didn't even bother with cable so all I had was  urlLink AFN  (American Forces Network) (that guy on the homepage is their 6:30 newsanchor...the very reason I like to inline/rollerblade from 6-8PM).  Even if you have cable you only get like 2-3 other 'B' movie stations...nothing to write home about.  Truth be told, though, AFN has a pretty good lineup and I get to learn all about opsec (operational security) and that the U.S. Army in Korea is looking for E-4s and E-5s (enlisted ranks) to be MPs (Military Police).  So if you can handle the G.I. ads AFN is pretty cool.  Anyways, I didn't remember so many ads for weight-loss programs, get-rich-quick schemes and fantastic kitchen products, but there they were.  Of course in Korea most people are pretty fit and they know the best way to get rich is to marry rich or work hard--there are some ads there for kitchen and cleaning product, though, proving that some things truly are universal.  One ad that did throw me, though, was one for a 'male enhancement' pill.  What?!?!?  You take a pill for a bigger willi?  One version even had about 30 allusions to 'wood' throughout it.  I thought it was a spoof...maybe it was...it was on CNBC during  urlLink The Dennis Miller Show .   If anyone knows, please comment.  Ok, back to my time here.  We went down to the clubhouse to have a dip (ya, it's a little swanky...but the pool is outside, so it's not super-swanky) and there were some 18-something gals there sunning themselves and gabbing.  Man, this is NOT Seoul.  For one thing, no one actually tries to get a tan in Korea.  They wear Darth Vader-inspired visors to keep out all the rays they can and everyone is totally covered up.  Even when exercising Korean have pants, long-sleeves,  even suits .  Also, two of the three of them were 'plus size'.  They weighed like 2-3 TIMES that of a typical Korean gal.  (Not that that's a bad thing...it's just differences...please, no flames.)  Then you have to think...if they are 18 aren't they still in school?  By that I mean, they have not graduated from college.  An 18-year old Korean would be in the library or at a DVD bang, at least.  Most likely not at a pool (and I hear they're there everyday for hours on end)...what a different lifestyle.  Even after school is finished they'd be working or looking for a husband, or both.  Let's face it, many Koreans have little time to be idle (I must say, they do take time to drink and go to the sauna, though).  Maybe I'm becoming too Korean now, beating up these gals simply for having a little fun.  All I know is if they did that in Korea people might think they are  urlLink R.S.  (room salon, or places where men pay women to drink with them, sing with them and...uh...do other things) girls.  Maybe that's part of the Korean ideal.  Women should study and work and find a husband and if they are 'wasting' their time everyday then they must be of low moral fiber.  Hmmmm...there could be something to that.  Maybe it's part of the reason why so many Korean gals work their butts off (literally, Korean women are usually devoid of a derriere) and seem to push off their own pleasure in some Calvinist tradition.  Korean men seem to support this as it not only support the Confucius ideals that many Koreans follow but makes their place as symbolic leader of the home that much more solid (whether it is deserved or not, and we know that in many Korean homes a strong wife controls more than she advertises).         \""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 685 ms (started: 2021-10-31 11:51:18 +00:00)\n"
     ]
    }
   ],
   "source": [
    "blog_df.iloc[19].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d01f4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIx7kkaJFyV4",
    "outputId": "1b5915fd-92c0-4a22-cf78-3717fe982ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16662)\t1\n",
      "  (0, 30549)\t1\n",
      "  (0, 40179)\t1\n",
      "  (0, 67142)\t1\n",
      "  (0, 67876)\t1\n",
      "  (0, 68397)\t1\n",
      "  (0, 68711)\t1\n",
      "  (0, 71349)\t1\n",
      "  (0, 72503)\t1\n",
      "  (0, 74620)\t1\n",
      "  (0, 75631)\t2\n",
      "  (0, 76649)\t2\n",
      "  (0, 76747)\t1\n",
      "  (0, 79613)\t1\n",
      "  (0, 82824)\t1\n",
      "  (0, 83236)\t1\n",
      "  (0, 84249)\t1\n",
      "  (0, 84840)\t1\n",
      "  (0, 85857)\t1\n",
      "  (0, 85960)\t1\n",
      "  (0, 86128)\t2\n",
      "  (0, 86640)\t1\n",
      "  (0, 87927)\t1\n",
      "  (0, 89530)\t1\n",
      "  (0, 91749)\t1\n",
      "  :\t:\n",
      "  (0, 122727)\t1\n",
      "  (0, 123338)\t2\n",
      "  (0, 125988)\t2\n",
      "  (0, 127407)\t1\n",
      "  (0, 133237)\t1\n",
      "  (0, 135240)\t1\n",
      "  (0, 137454)\t4\n",
      "  (0, 144432)\t1\n",
      "  (0, 145367)\t2\n",
      "  (0, 146587)\t1\n",
      "  (0, 147737)\t1\n",
      "  (0, 147928)\t1\n",
      "  (0, 147939)\t1\n",
      "  (0, 147981)\t1\n",
      "  (0, 148159)\t1\n",
      "  (0, 148940)\t1\n",
      "  (0, 149103)\t1\n",
      "  (0, 149152)\t1\n",
      "  (0, 149849)\t1\n",
      "  (0, 151018)\t1\n",
      "  (0, 156435)\t2\n",
      "  (0, 156791)\t1\n",
      "  (0, 157050)\t1\n",
      "  (0, 159771)\t1\n",
      "  (0, 159949)\t1\n",
      "time: 9.89 ms (started: 2021-10-31 11:51:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#What's there in sparse matrix\n",
    "print(X_train_ct[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b1a7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WX8XRm9oOhvO",
    "outputId": "9febb0ff-3756-4c1e-b3f5-ccc61f2f917f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170321, 160634)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.01 ms (started: 2021-10-31 11:51:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "X_test_ct.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e494a5e",
   "metadata": {
    "id": "Xvwbdk3mMOwe"
   },
   "source": [
    "  Design, train, tune and test the best text classifier for Approach #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac33d8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBc9fgzIOi7k",
    "outputId": "1ac27aaf-f8df-498c-fe5a-b4227add11fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 60.3 ms (started: 2021-10-31 13:03:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9dad6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v2cs1LmOkYT",
    "outputId": "3cc1a935-feba-40d1-899f-524e10cfc0bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 320 ms (started: 2021-10-31 13:03:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model (with the default parameters)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# fit the model with data (occurs in-place)\n",
    "knn.fit(X_train_ct, y_topic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a48ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CW13vL3lOx7a",
    "outputId": "7ed26f50-7fba-4728-e743-63558491d287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Train Accuracy 0.4512\n",
      "KNN Test Accuracy 0.2472\n",
      "time: 18.2 s (started: 2021-10-31 13:03:34 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "### Calculate accuracy on Training Dataset\n",
    "print(\"KNN Train Accuracy\", metrics.accuracy_score(y_topic_train, knn.predict(X_train_ct)))\n",
    "#Calculate accuracy on Test Dataset\n",
    "prediction_knn = knn.predict(X_test_ct)\n",
    "print(\"KNN Test Accuracy\", metrics.accuracy_score(y_topic_test, prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1d47f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0BFnVrHHUSj",
    "outputId": "88b0eb20-0aaa-4f83-d484-108c5c69698a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                Student       0.00      0.00      0.00        11\n",
      "      InvestmentBanking       0.15      0.18      0.17        11\n",
      "                 indUnk       0.02      0.29      0.05        14\n",
      "             Non-Profit       0.00      0.00      0.00        17\n",
      "                Banking       0.05      0.02      0.03        89\n",
      "              Education       0.25      0.04      0.07        25\n",
      "            Engineering       0.00      0.00      0.00        18\n",
      "                Science       0.00      0.00      0.00        11\n",
      "   Communications-Media       0.12      0.07      0.09        41\n",
      "       BusinessServices       0.07      0.40      0.12       108\n",
      "      Sports-Recreation       0.00      0.00      0.00         8\n",
      "                   Arts       0.00      0.00      0.00        34\n",
      "               Internet       0.27      0.07      0.11       212\n",
      "      Museums-Libraries       0.04      0.01      0.02        86\n",
      "             Accounting       0.16      0.10      0.13       386\n",
      "             Technology       0.00      0.00      0.00        41\n",
      "                    Law       0.00      0.00      0.00         4\n",
      "             Consulting       0.09      0.10      0.09       213\n",
      "             Automotive       0.00      0.00      0.00        19\n",
      "               Religion       0.00      0.00      0.00        15\n",
      "                Fashion       0.08      0.04      0.05        28\n",
      "             Publishing       0.00      0.00      0.00        25\n",
      "              Marketing       0.25      0.02      0.04        41\n",
      "LawEnforcement-Security       0.00      0.00      0.00         4\n",
      "         HumanResources       0.00      0.00      0.00        15\n",
      "     Telecommunications       1.00      0.02      0.03        60\n",
      "               Military       0.00      0.00      0.00        11\n",
      "             Government       0.00      0.00      0.00         1\n",
      "         Transportation       0.29      0.10      0.15        41\n",
      "           Architecture       0.50      0.05      0.08        22\n",
      "            Advertising       0.67      0.06      0.11        32\n",
      "            Agriculture       0.22      0.16      0.19       658\n",
      "                Biotech       0.21      0.35      0.26       747\n",
      "             RealEstate       0.00      0.00      0.00         3\n",
      "          Manufacturing       0.00      0.00      0.00        12\n",
      "           Construction       0.43      0.37      0.40      1937\n",
      "\n",
      "               accuracy                           0.25      5000\n",
      "              macro avg       0.13      0.07      0.06      5000\n",
      "           weighted avg       0.28      0.25      0.25      5000\n",
      "\n",
      "time: 816 ms (started: 2021-10-31 13:03:52 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_names = blog_df['topic'].unique()\n",
    "cm = classification_report(y_topic_test, prediction_knn, target_names=target_names)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dea93a",
   "metadata": {
    "id": "FBFOa8imIjlz"
   },
   "source": [
    "  As we can see in above result, the accuracy which signifies ratio of correctly predicted observation to the total observations is at good score for single label prediction. Here we have considered topic label which is having many classes and when compared this label with text column there are more corellation between the words in the text column and the topic label and this could be one of the reason for getting good accuracy score. Precision is the ratio of correctly predicted positive observations to the total predicted positive observations, When we observe the same for Law topic it is showing high score and we can relate to this since there will be unique words which are related to law and hence the topic will be marked approriately. For this use case precision is important and should be observed closely. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc315fd",
   "metadata": {
    "id": "tSyT5_iwKV5c"
   },
   "source": [
    "  Lets run the SVC on same data and check the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360aef77",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXUNkX6XO25j",
    "outputId": "cccab5ba-41fe-47fc-c947-5a6f353ddbbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy on Training Dataset  0.5366\n",
      " Accuracy on Test Dataset  0.41\n",
      "time: 7min 51s (started: 2021-10-31 13:03:53 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "####Train an SVM with default parameters\n",
    "svc = SVC()\n",
    "svc.fit(X_train_ct, y_topic_train)\n",
    "### Calculate accuracy on Training Dataset\n",
    "print(\" Accuracy on Training Dataset \" , metrics.accuracy_score(y_topic_train, svc.predict(X_train_ct)))\n",
    "####Calculate accuracy on Test Dataset\n",
    "prediction = svc.predict(X_test_ct)\n",
    "print(\" Accuracy on Test Dataset \", metrics.accuracy_score(y_topic_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6d97a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X38BIiBb9xmp",
    "outputId": "ba730376-2239-4749-edb9-f133d167ffc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                Student       0.00      0.00      0.00        11\n",
      "      InvestmentBanking       0.00      0.00      0.00        11\n",
      "                 indUnk       0.00      0.00      0.00        14\n",
      "             Non-Profit       0.00      0.00      0.00        17\n",
      "                Banking       0.00      0.00      0.00        89\n",
      "              Education       1.00      0.12      0.21        25\n",
      "            Engineering       0.00      0.00      0.00        18\n",
      "                Science       0.00      0.00      0.00        11\n",
      "   Communications-Media       1.00      0.02      0.05        41\n",
      "       BusinessServices       0.00      0.00      0.00       108\n",
      "      Sports-Recreation       0.00      0.00      0.00         8\n",
      "                   Arts       0.00      0.00      0.00        34\n",
      "               Internet       1.00      0.02      0.04       212\n",
      "      Museums-Libraries       0.00      0.00      0.00        86\n",
      "             Accounting       0.94      0.12      0.21       386\n",
      "             Technology       0.00      0.00      0.00        41\n",
      "                    Law       0.00      0.00      0.00         4\n",
      "             Consulting       0.00      0.00      0.00       213\n",
      "             Automotive       0.00      0.00      0.00        19\n",
      "               Religion       0.00      0.00      0.00        15\n",
      "                Fashion       0.00      0.00      0.00        28\n",
      "             Publishing       0.00      0.00      0.00        25\n",
      "              Marketing       1.00      0.12      0.22        41\n",
      "LawEnforcement-Security       0.00      0.00      0.00         4\n",
      "         HumanResources       0.00      0.00      0.00        15\n",
      "     Telecommunications       0.00      0.00      0.00        60\n",
      "               Military       0.00      0.00      0.00        11\n",
      "             Government       0.00      0.00      0.00         1\n",
      "         Transportation       0.00      0.00      0.00        41\n",
      "           Architecture       0.00      0.00      0.00        22\n",
      "            Advertising       1.00      0.03      0.06        32\n",
      "            Agriculture       0.88      0.03      0.07       658\n",
      "                Biotech       0.88      0.05      0.09       747\n",
      "             RealEstate       0.00      0.00      0.00         3\n",
      "          Manufacturing       0.00      0.00      0.00        12\n",
      "           Construction       0.40      1.00      0.57      1937\n",
      "\n",
      "               accuracy                           0.41      5000\n",
      "              macro avg       0.22      0.04      0.04      5000\n",
      "           weighted avg       0.54      0.41      0.26      5000\n",
      "\n",
      "time: 477 ms (started: 2021-10-31 13:11:44 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_topic_test, prediction, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352530e3",
   "metadata": {
    "id": "nWL-YZYDKry-"
   },
   "source": [
    "  The score given by accuracy is better than knn and we can observe good results in the precision for many labels like Communications-Media, Law. Using SVC for single label classification seems provide more precise result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910c55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145cf93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47331e9d",
   "metadata": {
    "id": "hsx8QQL6MhIy"
   },
   "source": [
    "  TF-IDF vectorization technique will be implemented in below cells. Again, we are applying alogorithm on text against single label. This is approach #1 but with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd018b87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUNNFbky9xqA",
    "outputId": "e310fce4-78f6-4759-ce14-3ef9eaf9210c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.6 s (started: 2021-10-31 11:37:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(blog_df, random_state=2, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03137823",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFCFueQzNRQp",
    "outputId": "e579977b-81d0-4a06-d8a4-3034f4344489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456460,)\n",
      "(224824,)\n",
      "time: 37.7 ms (started: 2021-10-31 11:37:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.text\n",
    "X_test = test.text\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a476e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFA5Txe29xtC",
    "outputId": "59db892c-d7c0-44db-e557-2ffdf9803dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.7 ms (started: 2021-10-31 11:37:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be7a03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVt0pzwSNxn8",
    "outputId": "d42ab6ca-3b03-4dee-86b7-f6492ca0a981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.93 ms (started: 2021-10-31 11:37:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def trim(s):\n",
    "    if(s != 'age'):\n",
    "      clm_name = s[ : -3]\n",
    "    else:\n",
    "      clm_name = 'age'\n",
    "    return  clm_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4957b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzT5nliIOSgK",
    "outputId": "1b8400b4-0c26-47d0-e2c2-d0787c7e4ea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "... Processing gender_le\n",
      "Test accuracy is 0.6884273920933708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.66      0.75      0.70    110795\n",
      "      female       0.72      0.63      0.67    114029\n",
      "\n",
      "    accuracy                           0.69    224824\n",
      "   macro avg       0.69      0.69      0.69    224824\n",
      "weighted avg       0.69      0.69      0.69    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing sign_le\n",
      "Test accuracy is 0.23025566665480554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Leo       0.72      0.08      0.14     16428\n",
      "    Aquarius       0.22      0.43      0.29     21441\n",
      "       Aries       0.15      0.62      0.24     21571\n",
      "   Capricorn       0.68      0.04      0.07     16257\n",
      "      Gemini       0.65      0.07      0.12     17121\n",
      "      Cancer       0.57      0.08      0.15     17684\n",
      " Sagittarius       0.23      0.33      0.27     20692\n",
      "     Scorpio       0.59      0.11      0.19     17947\n",
      "       Libra       0.71      0.07      0.12     16452\n",
      "       Virgo       0.50      0.15      0.23     18735\n",
      "      Taurus       0.26      0.30      0.28     20720\n",
      "      Pisces       0.26      0.29      0.27     19776\n",
      "\n",
      "    accuracy                           0.23    224824\n",
      "   macro avg       0.46      0.21      0.20    224824\n",
      "weighted avg       0.44      0.23      0.20    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing topic_le\n",
      "Test accuracy is 0.3941838949578337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                Student       0.00      0.00      0.00      1252\n",
      "      InvestmentBanking       0.91      0.01      0.01      1547\n",
      "                 indUnk       0.00      0.00      0.00       403\n",
      "             Non-Profit       0.00      0.00      0.00       555\n",
      "                Banking       0.69      0.00      0.00     10658\n",
      "              Education       0.00      0.00      0.00       419\n",
      "            Engineering       0.00      0.00      0.00      1366\n",
      "                Science       0.00      0.00      0.00       737\n",
      "   Communications-Media       0.00      0.00      0.00      1481\n",
      "       BusinessServices       0.00      0.00      0.00      1348\n",
      "      Sports-Recreation       0.97      0.00      0.01      6667\n",
      "                   Arts       0.00      0.00      0.00       373\n",
      "               Internet       0.00      0.00      0.00      1962\n",
      "      Museums-Libraries       0.65      0.01      0.01      9853\n",
      "             Accounting       0.89      0.00      0.00      3836\n",
      "             Technology       0.00      0.00      0.00       177\n",
      "                    Law       1.00      0.00      0.00      1653\n",
      "             Consulting       0.85      0.01      0.01      2259\n",
      "             Automotive       0.00      0.00      0.00      1030\n",
      "               Religion       0.79      0.00      0.00      5244\n",
      "                Fashion       0.00      0.00      0.00       439\n",
      "             Publishing       1.00      0.00      0.00      2933\n",
      "              Marketing       0.00      0.00      0.00       619\n",
      "LawEnforcement-Security       0.00      0.00      0.00       745\n",
      "         HumanResources       0.00      0.00      0.00        98\n",
      "     Telecommunications       0.00      0.00      0.00      1525\n",
      "               Military       0.00      0.00      0.00      1010\n",
      "             Government       0.00      0.00      0.00      1033\n",
      "         Transportation       0.88      0.00      0.01      4841\n",
      "           Architecture       1.00      0.00      0.00      2552\n",
      "            Advertising       0.00      0.00      0.00       969\n",
      "            Agriculture       0.00      0.00      0.00      1733\n",
      "                Biotech       0.56      0.01      0.01      2319\n",
      "             RealEstate       0.00      0.00      0.00       985\n",
      "          Manufacturing       0.62      0.16      0.25     50694\n",
      "           Construction       0.74      0.01      0.03     13938\n",
      "              Chemicals       0.00      0.00      0.00      1277\n",
      "               Maritime       0.00      0.00      0.00       655\n",
      "                Tourism       0.00      0.00      0.00       754\n",
      "            Environment       0.38      0.97      0.55     82885\n",
      "\n",
      "               accuracy                           0.39    224824\n",
      "              macro avg       0.30      0.03      0.02    224824\n",
      "           weighted avg       0.52      0.39      0.26    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing age\n",
      "Test accuracy is 0.23858217983845142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          15       0.92      0.01      0.01      4341\n",
      "          33       0.90      0.04      0.08      8969\n",
      "          14       0.84      0.03      0.06     13931\n",
      "          25       0.49      0.24      0.32     24046\n",
      "          17       0.25      0.73      0.37     26683\n",
      "          23       0.41      0.16      0.23     24171\n",
      "          37       0.16      0.73      0.27     26164\n",
      "          26       0.49      0.09      0.16     22199\n",
      "          24       0.73      0.06      0.11     18195\n",
      "          27       0.70      0.03      0.06     15084\n",
      "          45       1.00      0.00      0.00      5855\n",
      "          34       0.99      0.03      0.07      7161\n",
      "          41       0.95      0.02      0.03      5801\n",
      "          44       1.00      0.00      0.01      4712\n",
      "          16       1.00      0.01      0.02      3076\n",
      "          39       1.00      0.01      0.02      2466\n",
      "          35       0.00      0.00      0.00      1840\n",
      "          36       1.00      0.18      0.31      1660\n",
      "          46       0.00      0.00      0.00      1278\n",
      "          42       0.00      0.00      0.00       939\n",
      "          13       0.00      0.00      0.00      1358\n",
      "          38       0.00      0.00      0.00       688\n",
      "          43       0.00      0.00      0.00      1446\n",
      "          40       0.00      0.00      0.00       869\n",
      "          47       0.00      0.00      0.00       736\n",
      "          48       0.00      0.00      0.00      1156\n",
      "\n",
      "    accuracy                           0.24    224824\n",
      "   macro avg       0.49      0.09      0.08    224824\n",
      "weighted avg       0.54      0.24      0.18    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "time: 9min 40s (started: 2021-10-31 11:37:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define a pipeline combining a text feature extractor with multi lable classifier\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None), n_jobs = -1)),\n",
    "            ])\n",
    "    \n",
    "categories = ['gender_le', 'sign_le' , 'topic_le',  'age']\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction_C_NB_OVR = NB_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction_C_NB_OVR)))\n",
    "    target_names = [str(names) for names in blog_df[trim(category)].unique()] \n",
    "    cm = classification_report(test[category], prediction_C_NB_OVR, target_names=target_names)\n",
    "    print(cm)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d63ba8",
   "metadata": {},
   "source": [
    "    When we look at classification report for individual labels we observe that the model has some room for improvement. Although it is having good precision score compared to recall, but the score are not in acceptable range. A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01aa42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xONzWMRHbtMr",
    "outputId": "5d4e1233-9465-4565-f414-a322905dc835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing gender_le\n",
      "Test accuracy is 0.7162180194285308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.72      0.70      0.71    110795\n",
      "      female       0.72      0.73      0.72    114029\n",
      "\n",
      "    accuracy                           0.72    224824\n",
      "   macro avg       0.72      0.72      0.72    224824\n",
      "weighted avg       0.72      0.72      0.72    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing sign_le\n",
      "Test accuracy is 0.28734031953883926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Leo       0.31      0.28      0.29     16428\n",
      "    Aquarius       0.29      0.35      0.31     21441\n",
      "       Aries       0.30      0.31      0.31     21571\n",
      "   Capricorn       0.27      0.24      0.26     16257\n",
      "      Gemini       0.28      0.27      0.28     17121\n",
      "      Cancer       0.28      0.27      0.28     17684\n",
      " Sagittarius       0.27      0.29      0.28     20692\n",
      "     Scorpio       0.31      0.29      0.30     17947\n",
      "       Libra       0.30      0.25      0.27     16452\n",
      "       Virgo       0.28      0.28      0.28     18735\n",
      "      Taurus       0.28      0.30      0.29     20720\n",
      "      Pisces       0.28      0.29      0.29     19776\n",
      "\n",
      "    accuracy                           0.29    224824\n",
      "   macro avg       0.29      0.29      0.29    224824\n",
      "weighted avg       0.29      0.29      0.29    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing topic_le\n",
      "Test accuracy is 0.46132530334839694\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                Student       0.40      0.16      0.23      1252\n",
      "      InvestmentBanking       0.57      0.14      0.22      1547\n",
      "                 indUnk       0.66      0.11      0.19       403\n",
      "             Non-Profit       0.39      0.08      0.13       555\n",
      "                Banking       0.45      0.20      0.28     10658\n",
      "              Education       0.24      0.03      0.05       419\n",
      "            Engineering       0.46      0.12      0.19      1366\n",
      "                Science       0.46      0.15      0.23       737\n",
      "   Communications-Media       0.68      0.18      0.29      1481\n",
      "       BusinessServices       0.32      0.07      0.12      1348\n",
      "      Sports-Recreation       0.42      0.15      0.22      6667\n",
      "                   Arts       0.64      0.12      0.20       373\n",
      "               Internet       0.48      0.10      0.16      1962\n",
      "      Museums-Libraries       0.49      0.21      0.29      9853\n",
      "             Accounting       0.51      0.18      0.27      3836\n",
      "             Technology       0.10      0.05      0.07       177\n",
      "                    Law       0.76      0.33      0.46      1653\n",
      "             Consulting       0.62      0.15      0.25      2259\n",
      "             Automotive       0.39      0.09      0.14      1030\n",
      "               Religion       0.47      0.16      0.24      5244\n",
      "                Fashion       0.69      0.09      0.15       439\n",
      "             Publishing       0.47      0.19      0.27      2933\n",
      "              Marketing       0.71      0.19      0.30       619\n",
      "LawEnforcement-Security       0.65      0.12      0.21       745\n",
      "         HumanResources       0.09      0.01      0.02        98\n",
      "     Telecommunications       0.28      0.08      0.12      1525\n",
      "               Military       0.58      0.13      0.22      1010\n",
      "             Government       0.41      0.16      0.23      1033\n",
      "         Transportation       0.39      0.13      0.20      4841\n",
      "           Architecture       0.60      0.24      0.35      2552\n",
      "            Advertising       0.55      0.18      0.28       969\n",
      "            Agriculture       0.50      0.16      0.24      1733\n",
      "                Biotech       0.34      0.10      0.16      2319\n",
      "             RealEstate       0.62      0.13      0.22       985\n",
      "          Manufacturing       0.46      0.52      0.49     50694\n",
      "           Construction       0.42      0.26      0.32     13938\n",
      "              Chemicals       0.60      0.18      0.28      1277\n",
      "               Maritime       0.65      0.23      0.34       655\n",
      "                Tourism       0.82      0.22      0.35       754\n",
      "            Environment       0.46      0.74      0.57     82885\n",
      "\n",
      "               accuracy                           0.46    224824\n",
      "              macro avg       0.50      0.17      0.24    224824\n",
      "           weighted avg       0.47      0.46      0.42    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing age\n",
      "Test accuracy is 0.3622389068782692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          15       0.52      0.33      0.40      4341\n",
      "          33       0.46      0.36      0.40      8969\n",
      "          14       0.43      0.38      0.40     13931\n",
      "          25       0.41      0.46      0.43     24046\n",
      "          17       0.41      0.51      0.45     26683\n",
      "          23       0.32      0.37      0.34     24171\n",
      "          37       0.30      0.37      0.33     26164\n",
      "          26       0.32      0.35      0.33     22199\n",
      "          24       0.32      0.31      0.31     18195\n",
      "          27       0.30      0.27      0.29     15084\n",
      "          45       0.38      0.23      0.29      5855\n",
      "          34       0.43      0.37      0.40      7161\n",
      "          41       0.36      0.25      0.30      5801\n",
      "          44       0.38      0.25      0.30      4712\n",
      "          16       0.43      0.26      0.32      3076\n",
      "          39       0.39      0.20      0.27      2466\n",
      "          35       0.35      0.16      0.22      1840\n",
      "          36       0.61      0.35      0.45      1660\n",
      "          46       0.46      0.20      0.28      1278\n",
      "          42       0.35      0.19      0.24       939\n",
      "          13       0.46      0.25      0.33      1358\n",
      "          38       0.50      0.23      0.31       688\n",
      "          43       0.43      0.25      0.32      1446\n",
      "          40       0.30      0.20      0.24       869\n",
      "          47       0.63      0.32      0.42       736\n",
      "          48       0.59      0.41      0.48      1156\n",
      "\n",
      "    accuracy                           0.36    224824\n",
      "   macro avg       0.42      0.30      0.34    224824\n",
      "weighted avg       0.37      0.36      0.36    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "time: 16min 6s (started: 2021-10-31 11:47:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction_C_SVC_OVR = SVC_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction_C_SVC_OVR)))\n",
    "    target_names = [str(names) for names in blog_df[trim(category)].unique()] \n",
    "    cm = classification_report(test[category], prediction_C_SVC_OVR, target_names=target_names)\n",
    "    print(cm)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b96187",
   "metadata": {},
   "source": [
    "    Application of linear SVC on the data has improved when compared with MultinomialNB classifier. But lets check with LogisticRegression classifier before concluding on the final good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a3bff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_uspWDWJD__",
    "outputId": "4c5b2bd2-e296-41ef-b3ac-2826e5bccb35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing gender_le\n",
      "Test accuracy is 0.7129043162651674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.72      0.69      0.70    110795\n",
      "      female       0.71      0.73      0.72    114029\n",
      "\n",
      "    accuracy                           0.71    224824\n",
      "   macro avg       0.71      0.71      0.71    224824\n",
      "weighted avg       0.71      0.71      0.71    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing sign_le\n",
      "Test accuracy is 0.2573390741202007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Leo       0.30      0.22      0.26     16428\n",
      "    Aquarius       0.25      0.35      0.29     21441\n",
      "       Aries       0.26      0.31      0.28     21571\n",
      "   Capricorn       0.27      0.19      0.22     16257\n",
      "      Gemini       0.26      0.22      0.23     17121\n",
      "      Cancer       0.25      0.22      0.24     17684\n",
      " Sagittarius       0.24      0.28      0.25     20692\n",
      "     Scorpio       0.30      0.25      0.27     17947\n",
      "       Libra       0.29      0.20      0.24     16452\n",
      "       Virgo       0.25      0.24      0.25     18735\n",
      "      Taurus       0.24      0.28      0.26     20720\n",
      "      Pisces       0.25      0.28      0.26     19776\n",
      "\n",
      "    accuracy                           0.26    224824\n",
      "   macro avg       0.26      0.25      0.25    224824\n",
      "weighted avg       0.26      0.26      0.26    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing topic_le\n",
      "Test accuracy is 0.4410294274632601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                Student       0.47      0.06      0.11      1252\n",
      "      InvestmentBanking       0.90      0.02      0.05      1547\n",
      "                 indUnk       1.00      0.00      0.01       403\n",
      "             Non-Profit       0.50      0.00      0.01       555\n",
      "                Banking       0.66      0.09      0.16     10658\n",
      "              Education       0.00      0.00      0.00       419\n",
      "            Engineering       0.84      0.03      0.05      1366\n",
      "                Science       0.84      0.04      0.08       737\n",
      "   Communications-Media       0.91      0.08      0.14      1481\n",
      "       BusinessServices       0.55      0.00      0.01      1348\n",
      "      Sports-Recreation       0.65      0.04      0.08      6667\n",
      "                   Arts       1.00      0.03      0.06       373\n",
      "               Internet       0.68      0.01      0.01      1962\n",
      "      Museums-Libraries       0.66      0.09      0.15      9853\n",
      "             Accounting       0.82      0.07      0.13      3836\n",
      "             Technology       0.00      0.00      0.00       177\n",
      "                    Law       0.94      0.19      0.32      1653\n",
      "             Consulting       0.95      0.06      0.12      2259\n",
      "             Automotive       0.62      0.01      0.02      1030\n",
      "               Religion       0.66      0.06      0.10      5244\n",
      "                Fashion       1.00      0.00      0.00       439\n",
      "             Publishing       0.53      0.05      0.09      2933\n",
      "              Marketing       1.00      0.02      0.04       619\n",
      "LawEnforcement-Security       0.89      0.01      0.02       745\n",
      "         HumanResources       0.00      0.00      0.00        98\n",
      "     Telecommunications       0.61      0.02      0.04      1525\n",
      "               Military       1.00      0.02      0.04      1010\n",
      "             Government       0.60      0.05      0.10      1033\n",
      "         Transportation       0.60      0.06      0.10      4841\n",
      "           Architecture       0.89      0.11      0.19      2552\n",
      "            Advertising       0.37      0.02      0.03       969\n",
      "            Agriculture       0.44      0.05      0.08      1733\n",
      "                Biotech       0.71      0.03      0.05      2319\n",
      "             RealEstate       0.95      0.02      0.04       985\n",
      "          Manufacturing       0.48      0.46      0.47     50694\n",
      "           Construction       0.52      0.15      0.24     13938\n",
      "              Chemicals       0.93      0.06      0.11      1277\n",
      "               Maritime       0.96      0.04      0.07       655\n",
      "                Tourism       1.00      0.14      0.25       754\n",
      "            Environment       0.42      0.83      0.56     82885\n",
      "\n",
      "               accuracy                           0.44    224824\n",
      "              macro avg       0.69      0.08      0.10    224824\n",
      "           weighted avg       0.54      0.44      0.36    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "... Processing age\n",
      "Test accuracy is 0.3240312422161335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          15       0.70      0.16      0.26      4341\n",
      "          33       0.53      0.24      0.33      8969\n",
      "          14       0.45      0.28      0.35     13931\n",
      "          25       0.37      0.44      0.40     24046\n",
      "          17       0.36      0.53      0.43     26683\n",
      "          23       0.28      0.35      0.31     24171\n",
      "          37       0.24      0.42      0.30     26164\n",
      "          26       0.27      0.33      0.30     22199\n",
      "          24       0.29      0.26      0.28     18195\n",
      "          27       0.28      0.22      0.25     15084\n",
      "          45       0.53      0.12      0.20      5855\n",
      "          34       0.51      0.27      0.36      7161\n",
      "          41       0.54      0.17      0.26      5801\n",
      "          44       0.63      0.15      0.24      4712\n",
      "          16       0.63      0.12      0.21      3076\n",
      "          39       0.67      0.08      0.14      2466\n",
      "          35       0.75      0.05      0.09      1840\n",
      "          36       0.93      0.26      0.41      1660\n",
      "          46       0.84      0.03      0.06      1278\n",
      "          42       0.49      0.07      0.12       939\n",
      "          13       0.69      0.09      0.17      1358\n",
      "          38       0.77      0.05      0.09       688\n",
      "          43       0.71      0.10      0.17      1446\n",
      "          40       0.39      0.12      0.18       869\n",
      "          47       0.82      0.17      0.28       736\n",
      "          48       0.75      0.22      0.34      1156\n",
      "\n",
      "    accuracy                           0.32    224824\n",
      "   macro avg       0.55      0.20      0.25    224824\n",
      "weighted avg       0.38      0.32      0.31    224824\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "time: 40min 17s (started: 2021-10-31 12:03:18 +00:00)\n"
     ]
    }
   ],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction_C_LR_OVR = LogReg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction_C_LR_OVR)))\n",
    "    target_names = [str(names) for names in blog_df[trim(category)].unique()] \n",
    "    cm = classification_report(test[category], prediction_C_LR_OVR, target_names=target_names)\n",
    "    print(cm)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac3520",
   "metadata": {
    "id": "2-xP9BF9LWhd"
   },
   "source": [
    "    The above cell contains LogisticRegression classifier which is run on individual labels. For gender label, it is having 71% macro average and 71% recall. This single label classification and hence we can consider the macro avg. An ideal system with high precision and high recall will return many results, with all results labeled correctly. The sign label is having many classes and LogisticRegression has not performed well in this classification. Both recall and precision are low. The topic label is having 69% precision macro average and when we look into individual classes it has performed pretty much good, but there is lot of room for improvement. When we look into each class of the age label, we can observe that the model performance is good for this label.\n",
    "    When we apply classifier on individual labels, we observe that it is having good individual accuracy and good precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c025a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243cb9f",
   "metadata": {
    "id": "2-xP9BF9LWhd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c79896",
   "metadata": {
    "id": "kfGLT9-1M74F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ee3f5e",
   "metadata": {
    "id": "5uUD2Fd7OH7O"
   },
   "source": [
    "  Approach #2: In this approach a multiclass label is used prediction. The same cleansed text is used as X variable but Y variable is merged lables in the data set. Here we are merging 4 column - Gender, age, topic and sign. Upon this we are going to apply algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80775946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "rL-Lf3LMM7-M",
    "outputId": "617ee23d-77c8-4271-a725-9f50fffcf03a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>gender_le</th>\n",
       "      <th>topic_le</th>\n",
       "      <th>sign_le</th>\n",
       "      <th>label_four_column</th>\n",
       "      <th>label_three_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>find 100 45 now wait untill team leader</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "      <td>[male, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>these team van mail mail mail</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "      <td>[male, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>in het van how build from subject how to build...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "      <td>[male, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>test test</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "      <td>[male, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>thanks i capture i show cool link pop audio vi...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "      <td>[male, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "      <td>dear i could write really bitter diatribe dise...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>[male, 23, Student, Taurus]</td>\n",
       "      <td>[male, Student, Taurus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "      <td>dear i second yeast infection past two straigh...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>[male, 23, Student, Taurus]</td>\n",
       "      <td>[male, Student, Taurus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "      <td>dear your bald good luck</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>[male, 23, Student, Taurus]</td>\n",
       "      <td>[male, Student, Taurus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "      <td>dear just clarify i leave house why piss floor...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>[male, 23, Student, Taurus]</td>\n",
       "      <td>[male, Student, Taurus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "      <td>hey you might already know my weird al i get t...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>[male, 23, Student, Taurus]</td>\n",
       "      <td>[male, Student, Taurus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681284 rows x 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  ...                   label_three_column\n",
       "0       2059027  ...                 [male, Student, Leo]\n",
       "1       2059027  ...                 [male, Student, Leo]\n",
       "2       2059027  ...                 [male, Student, Leo]\n",
       "3       2059027  ...                 [male, Student, Leo]\n",
       "4       3581210  ...  [male, InvestmentBanking, Aquarius]\n",
       "...         ...  ...                                  ...\n",
       "681279  1713845  ...              [male, Student, Taurus]\n",
       "681280  1713845  ...              [male, Student, Taurus]\n",
       "681281  1713845  ...              [male, Student, Taurus]\n",
       "681282  1713845  ...              [male, Student, Taurus]\n",
       "681283  1713845  ...              [male, Student, Taurus]\n",
       "\n",
       "[681284 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 895 ms (started: 2021-10-31 11:32:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#check the variable creation before application of algorithm\n",
    "blog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f0945",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YCPno8mRm0l",
    "outputId": "8de191b9-26ea-46b6-f505-e2bb67f3db36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.75 ms (started: 2021-10-31 11:52:00 +00:00)\n"
     ]
    }
   ],
   "source": [
    "X= blog_df.Cleaned_text\n",
    "y = blog_df.label_four_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa549c61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiKn1HhjT6d2",
    "outputId": "d0844a58-9ed0-4e9a-d559-aec185124676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   find 100 45 now wait untill team leader\n",
       "1                             these team van mail mail mail\n",
       "2         in het van how build from subject how to build...\n",
       "3                                                 test test\n",
       "4         thanks i capture i show cool link pop audio vi...\n",
       "                                ...                        \n",
       "681279    dear i could write really bitter diatribe dise...\n",
       "681280    dear i second yeast infection past two straigh...\n",
       "681281                             dear your bald good luck\n",
       "681282    dear just clarify i leave house why piss floor...\n",
       "681283    hey you might already know my weird al i get t...\n",
       "Name: Cleaned_text, Length: 681284, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms (started: 2021-10-31 11:52:00 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#check content of variable X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53020a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kIaYu7BUoTm",
    "outputId": "ab8c234e-cc4a-4673-ffa7-7bfa884d8c29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        [male, 15, Student, Leo]\n",
       "1                        [male, 15, Student, Leo]\n",
       "2                        [male, 15, Student, Leo]\n",
       "3                        [male, 15, Student, Leo]\n",
       "4         [male, 33, InvestmentBanking, Aquarius]\n",
       "                           ...                   \n",
       "681279                [male, 23, Student, Taurus]\n",
       "681280                [male, 23, Student, Taurus]\n",
       "681281                [male, 23, Student, Taurus]\n",
       "681282                [male, 23, Student, Taurus]\n",
       "681283                [male, 23, Student, Taurus]\n",
       "Name: label_four_column, Length: 681284, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 87.5 ms (started: 2021-10-31 11:52:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#check content of variable y (label)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c65d02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtRlah0aRskN",
    "outputId": "10a8bf86-b9a3-44fd-8504-06d37dbe76f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17 s (started: 2021-10-31 11:52:04 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=2,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fc6de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4EV8PTlRvSB",
    "outputId": "b47b2213-efa6-4af4-86aa-160b3896f9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545027,)\n",
      "(545027,)\n",
      "(136257,)\n",
      "(136257,)\n",
      "time: 7.44 ms (started: 2021-10-31 11:52:21 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a217f6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COHQ1pEWM8Xo",
    "outputId": "e2e84950-10ca-4822-e396-17f3737a89b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.22 s (started: 2021-10-31 11:52:21 +00:00)\n"
     ]
    }
   ],
   "source": [
    "label_counts=dict()\n",
    "\n",
    "for labels in blog_df.label_four_column.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[str(label)]+=1\n",
    "        else:\n",
    "            label_counts[str(label)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8f5b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SkUmF2VSM-ry",
    "outputId": "f564e72f-0d9a-4610-9e3b-8edc79a5f767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.81 ms (started: 2021-10-31 11:52:24 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabb46b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1qpowUbNGs4",
    "outputId": "ff2c223c-d015-466f-d57f-befded7037c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: unknown class(es) [13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.27 s (started: 2021-10-31 11:52:24 +00:00)\n"
     ]
    }
   ],
   "source": [
    "y_train = binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a5de2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3Qaimq5NJtJ",
    "outputId": "4bcccdfa-6da3-4e81-dbca-7e7eee63ae92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 763 ms (started: 2021-10-31 11:52:27 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: unknown class(es) [13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48] will be ignored\n"
     ]
    }
   ],
   "source": [
    "y_test = binarizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68aefa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcSx1EqtR6K9",
    "outputId": "9fea4c3e-a470-4a7b-c261-f2174a543c32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "590624                                               canada\n",
       "197519    i dont see much scan burn future sorry unless ...\n",
       "147301    ko na papa ko gusto ko na ko yesterday sa sop ...\n",
       "114077                                 u clear grave pretty\n",
       "357895    so sitting work morning go normal get work rou...\n",
       "                                ...                        \n",
       "84434     wh0ot 620 morning sister give birth 7lb 13oz b...\n",
       "437782                                            and whats\n",
       "620104    hey today long say least i get super early i d...\n",
       "203245    a week i find laughter smile fatigue i feel go...\n",
       "100879    rio 12 04 9 farewell dinner larry restaurant i...\n",
       "Name: Cleaned_text, Length: 545027, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms (started: 2021-10-31 11:54:43 +00:00)\n"
     ]
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c40ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3Sf_yz4R9wg",
    "outputId": "928e6a23-31d4-4e8b-c4df-ba2e301850d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.41 ms (started: 2021-10-31 11:54:47 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#checking the label train variable.\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e240a74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6WMRrkvSAPK",
    "outputId": "37c44415-90dd-41a2-ef1f-c3c92e8bf87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(545027,)\n",
      "(545027, 80)\n",
      "(136257,)\n",
      "(136257, 80)\n",
      "time: 4.3 ms (started: 2021-10-31 11:54:48 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26077270",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N53Ql0k2SEBY",
    "outputId": "5df10248-074a-4a23-994a-4a1173e90ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.94 ms (started: 2021-10-31 11:54:49 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c044f4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUpvyu9liNYn",
    "outputId": "9b1b0ed6-5c89-4107-dfe3-0f6dfca5c7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 2s (started: 2021-10-31 12:05:42 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Initializing Vectorization of Climate posts\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "vectorised_train_documents = vectorizer.fit_transform(X_train)\n",
    "vectorised_test_documents = vectorizer.transform(X_test)\n",
    "# print(vectorised_train_documents)\n",
    "# print(vectorised_test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531a0ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXSjqF2dlXGV",
    "outputId": "5c82218a-df5e-40fa-de14-5446b431a81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 79590)\t1.0\n",
      "  (1, 79910)\t0.17057181818597883\n",
      "  (1, 118530)\t0.12588159449605357\n",
      "  (1, 122399)\t0.3234415935491709\n",
      "  (1, 133363)\t0.1448299584993193\n",
      "  (1, 162926)\t0.23118456027139778\n",
      "  (1, 96964)\t0.15932775889761905\n",
      "  (1, 99475)\t0.4190672832439514\n",
      "  (1, 154314)\t0.3792520880419818\n",
      "  (1, 152666)\t0.1247568853675155\n",
      "  (1, 125291)\t0.2823716840269498\n",
      "  (1, 138471)\t0.10278958687197529\n",
      "  (1, 72887)\t0.17302220036287563\n",
      "  (1, 158545)\t0.2178922214364242\n",
      "  (1, 147558)\t0.17958228080149802\n",
      "  (1, 97416)\t0.2030658161228118\n",
      "  (1, 78617)\t0.22485625892438985\n",
      "  (1, 142927)\t0.30197266721367716\n",
      "  (1, 123490)\t0.11148898231330266\n",
      "  (1, 143813)\t0.10294103116817388\n",
      "  (1, 89585)\t0.09823583393579922\n",
      "  (2, 114133)\t0.01519869835409899\n",
      "  (2, 156430)\t0.01914207129798274\n",
      "  (2, 98761)\t0.022588095622850957\n",
      "  (2, 103077)\t0.025983183368471875\n",
      "  :\t:\n",
      "  (545026, 84598)\t0.06013216562094178\n",
      "  (545026, 131303)\t0.04746643878376817\n",
      "  (545026, 100253)\t0.04824630396960745\n",
      "  (545026, 115420)\t0.11400508870882224\n",
      "  (545026, 102020)\t0.05280352006504346\n",
      "  (545026, 149073)\t0.050865267941689135\n",
      "  (545026, 115119)\t0.048420693953790644\n",
      "  (545026, 82909)\t0.09426342492540367\n",
      "  (545026, 151984)\t0.04128312331669412\n",
      "  (545026, 118355)\t0.03720596608575828\n",
      "  (545026, 98937)\t0.11842502934588708\n",
      "  (545026, 127783)\t0.05479509174718068\n",
      "  (545026, 101072)\t0.07424057279012258\n",
      "  (545026, 92978)\t0.03426402617923033\n",
      "  (545026, 74370)\t0.03308531760626894\n",
      "  (545026, 153597)\t0.03760831489786027\n",
      "  (545026, 99157)\t0.030037168804137964\n",
      "  (545026, 98431)\t0.02399267290815371\n",
      "  (545026, 145296)\t0.04690131318582504\n",
      "  (545026, 74542)\t0.04055282484180346\n",
      "  (545026, 101023)\t0.0459295241936285\n",
      "  (545026, 142800)\t0.09090788581324491\n",
      "  (545026, 118530)\t0.18835887576624866\n",
      "  (545026, 138471)\t0.03076117855226151\n",
      "  (545026, 143813)\t0.061613000625483735\n",
      "time: 388 ms (started: 2021-10-31 12:06:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(vectorised_train_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a19e3",
   "metadata": {},
   "source": [
    "    Lets check first 50 important words in the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e7eec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "prkxMVP9TFfC",
    "outputId": "81aee993-30b5-4988-99ee-70f0a9cee093"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.36 s (started: 2021-10-31 12:06:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from yellowbrick.text import FreqDistVisualizer\n",
    "features = vectorizer.get_feature_names()\n",
    "visualizer = FreqDistVisualizer(features=features, orient='v')\n",
    "visualizer.fit(vectorised_train_documents)\n",
    "visualizer;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1318286",
   "metadata": {},
   "source": [
    "    For evaluation of the model performance, we need to shall add the score to dictionary and try to display it at once. Here we are creating different score for checking models performance but we shall create the classification report at last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b2ed6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JopPXoBiihMV",
    "outputId": "0042fe1f-5c1b-4962-b377-815ca7823054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.4 ms (started: 2021-10-31 12:06:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ModelsPerformance = {}\n",
    "\n",
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    ModelsPerformance[modelName] = micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbbc8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtuJ2Yk4iiVA",
    "outputId": "890949b1-e945-4258-b388-c0fc87cd955f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.2 ms (started: 2021-10-31 12:06:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a1860",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTmX-OcLlNaE",
    "outputId": "c083dca3-a21f-41c2-af5d-aebb3e6f1357"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Label not 0 is present in all training examples.\n",
      "UserWarning: Label not 1 is present in all training examples.\n",
      "UserWarning: Label not 2 is present in all training examples.\n",
      "UserWarning: Label not 3 is present in all training examples.\n",
      "UserWarning: Label not 4 is present in all training examples.\n",
      "UserWarning: Label not 5 is present in all training examples.\n",
      "UserWarning: Label not 6 is present in all training examples.\n",
      "UserWarning: Label not 7 is present in all training examples.\n",
      "UserWarning: Label not 8 is present in all training examples.\n",
      "UserWarning: Label not 9 is present in all training examples.\n",
      "UserWarning: Label not 10 is present in all training examples.\n",
      "UserWarning: Label not 11 is present in all training examples.\n",
      "UserWarning: Label not 12 is present in all training examples.\n",
      "UserWarning: Label not 13 is present in all training examples.\n",
      "UserWarning: Label not 14 is present in all training examples.\n",
      "UserWarning: Label not 15 is present in all training examples.\n",
      "UserWarning: Label not 16 is present in all training examples.\n",
      "UserWarning: Label not 17 is present in all training examples.\n",
      "UserWarning: Label not 18 is present in all training examples.\n",
      "UserWarning: Label not 19 is present in all training examples.\n",
      "UserWarning: Label not 20 is present in all training examples.\n",
      "UserWarning: Label not 21 is present in all training examples.\n",
      "UserWarning: Label not 22 is present in all training examples.\n",
      "UserWarning: Label not 23 is present in all training examples.\n",
      "UserWarning: Label not 24 is present in all training examples.\n",
      "UserWarning: Label not 25 is present in all training examples.\n",
      "UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.5 s (started: 2021-10-31 12:06:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Model: Multinominal Naive Bayes\n",
    "nbClassifier = OneVsRestClassifier(MultinomialNB())\n",
    "nbClassifier.fit(vectorised_train_documents, y_train)\n",
    "nbPreds = nbClassifier.predict(vectorised_test_documents)\n",
    "metricsReport(nbClassifier, y_test, nbPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17576191",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfmtM8DHlgdi",
    "outputId": "f3322e4e-81f3-4fcf-cd37-b17dd0ff8e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                             fit_prior=True),\n",
       "                     n_jobs=None): 0.335220166942966}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.59 ms (started: 2021-10-31 12:07:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ModelsPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6edd86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFKkCw7QnSqC",
    "outputId": "704a1211-5a46-4f14-86da-e8f51f6830c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5min 19s (started: 2021-10-31 12:07:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "#Model: Linear Support Vector Machine\n",
    "svmClassifier = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svmClassifier.fit(vectorised_train_documents, y_train)\n",
    "svmPreds = svmClassifier.predict(vectorised_test_documents)\n",
    "metricsReport(svmClassifier, y_test, svmPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d9224",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfEdEg1inf8y",
    "outputId": "f13a3029-9200-43c3-afc5-e34b143ec40c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                         fit_intercept=True, intercept_scaling=1,\n",
       "                                         loss='squared_hinge', max_iter=1000,\n",
       "                                         multi_class='ovr', penalty='l2',\n",
       "                                         random_state=None, tol=0.0001,\n",
       "                                         verbose=0),\n",
       "                     n_jobs=-1): 0.1639066827968718,\n",
       " OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                             fit_prior=True),\n",
       "                     n_jobs=None): 0.335220166942966}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.97 ms (started: 2021-10-31 12:12:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ModelsPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909869b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAZR63x9D34v",
    "outputId": "83da8671-d313-4576-d7ea-65dbd9bf8c7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00       765\n",
      "          27       0.00      0.00      0.00       952\n",
      "          28       0.00      0.00      0.00       236\n",
      "          29       0.11      0.00      0.00      9798\n",
      "          30       0.00      0.00      0.00       336\n",
      "          31       0.32      0.00      0.01     12996\n",
      "          32       0.14      0.00      0.00      6464\n",
      "          33       0.00      0.00      0.00       276\n",
      "          34       0.00      0.00      0.00       840\n",
      "          35       0.00      0.00      0.00       457\n",
      "          36       0.00      0.00      0.00       907\n",
      "          37       0.81      0.02      0.04     13068\n",
      "          38       0.20      0.00      0.00      9842\n",
      "          39       0.00      0.00      0.00       823\n",
      "          40       0.09      0.00      0.00      4057\n",
      "          41       0.00      0.00      0.00       217\n",
      "          42       0.00      0.00      0.00      1218\n",
      "          43       0.04      0.00      0.00      5935\n",
      "          44       0.14      0.00      0.00      2349\n",
      "          45       0.00      0.00      0.00       107\n",
      "          46       0.00      0.00      0.00      1032\n",
      "          47       0.17      0.00      0.00     10418\n",
      "          48       0.00      0.00      0.00      1383\n",
      "          49       0.12      0.00      0.00       617\n",
      "          50       0.00      0.00      0.00      3130\n",
      "          51       0.00      0.00      0.00       263\n",
      "          52       0.00      0.00      0.00      1764\n",
      "          53       0.00      0.00      0.00       390\n",
      "          54       0.30      0.00      0.01     10749\n",
      "          55       0.22      0.00      0.00     12579\n",
      "          56       0.00      0.00      0.00       452\n",
      "          57       0.00      0.00      0.00        58\n",
      "          58       0.00      0.00      0.00       948\n",
      "          59       0.00      0.00      0.00       596\n",
      "          60       0.00      0.00      0.00       626\n",
      "          61       0.04      0.00      0.00      2935\n",
      "          62       0.34      0.00      0.01     10998\n",
      "          63       0.00      0.00      0.00      1550\n",
      "          64       0.00      0.00      0.00       574\n",
      "          65       0.00      0.00      0.00      1044\n",
      "          66       0.16      0.00      0.00      9936\n",
      "          67       0.00      0.00      0.00      1405\n",
      "          68       0.21      0.00      0.00     11492\n",
      "          69       0.11      0.00      0.00       609\n",
      "          70       0.66      0.03      0.05     30671\n",
      "          71       0.75      0.01      0.03     12539\n",
      "          72       0.30      0.00      0.01      8419\n",
      "          73       0.00      0.00      0.00       814\n",
      "          74       0.00      0.00      0.00       410\n",
      "          75       0.00      0.00      0.00       456\n",
      "          76       0.53      0.01      0.01     11842\n",
      "          77       0.64      0.70      0.67     67343\n",
      "          78       0.78      0.03      0.05     50172\n",
      "          79       0.68      0.61      0.64     68914\n",
      "\n",
      "   micro avg       0.65      0.23      0.34    408771\n",
      "   macro avg       0.10      0.02      0.02    408771\n",
      "weighted avg       0.50      0.23      0.23    408771\n",
      " samples avg       0.65      0.23      0.33    408771\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "time: 1.24 s (started: 2021-10-31 12:13:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cmNB = classification_report(y_test, nbPreds)\n",
    "print(cmNB)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2965f0",
   "metadata": {},
   "source": [
    "    In above cell, MultinomialNB classification report is shown and the model's predictions micro avergae precision is around 65% which has lot of room for improvement. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. Here one thing we can observe is that the macro avgs are having low score which means the claissifer is able to classify individual labels and collectively it is not having good score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3c0c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eP40cqVtEIum",
    "outputId": "45deb23e-10c6-4655-e961-f5c66bc1e6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00       765\n",
      "          27       1.00      0.01      0.02       952\n",
      "          28       0.00      0.00      0.00       236\n",
      "          29       0.90      0.01      0.02      9798\n",
      "          30       0.00      0.00      0.00       336\n",
      "          31       0.79      0.01      0.02     12996\n",
      "          32       0.86      0.01      0.03      6464\n",
      "          33       0.00      0.00      0.00       276\n",
      "          34       1.00      0.01      0.02       840\n",
      "          35       1.00      0.01      0.01       457\n",
      "          36       0.75      0.01      0.01       907\n",
      "          37       0.96      0.03      0.06     13068\n",
      "          38       0.92      0.00      0.01      9842\n",
      "          39       0.75      0.00      0.01       823\n",
      "          40       0.86      0.00      0.01      4057\n",
      "          41       0.00      0.00      0.00       217\n",
      "          42       1.00      0.00      0.00      1218\n",
      "          43       0.96      0.01      0.03      5935\n",
      "          44       0.52      0.00      0.01      2349\n",
      "          45       1.00      0.03      0.05       107\n",
      "          46       0.76      0.02      0.05      1032\n",
      "          47       0.87      0.01      0.02     10418\n",
      "          48       1.00      0.04      0.08      1383\n",
      "          49       1.00      0.00      0.00       617\n",
      "          50       0.95      0.01      0.01      3130\n",
      "          51       0.00      0.00      0.00       263\n",
      "          52       0.83      0.00      0.01      1764\n",
      "          53       1.00      0.01      0.01       390\n",
      "          54       0.96      0.01      0.02     10749\n",
      "          55       0.76      0.00      0.01     12579\n",
      "          56       0.00      0.00      0.00       452\n",
      "          57       0.00      0.00      0.00        58\n",
      "          58       1.00      0.01      0.03       948\n",
      "          59       1.00      0.00      0.00       596\n",
      "          60       1.00      0.00      0.01       626\n",
      "          61       0.85      0.00      0.01      2935\n",
      "          62       0.85      0.01      0.03     10998\n",
      "          63       0.96      0.04      0.08      1550\n",
      "          64       1.00      0.02      0.03       574\n",
      "          65       0.80      0.00      0.01      1044\n",
      "          66       0.88      0.01      0.01      9936\n",
      "          67       0.50      0.00      0.00      1405\n",
      "          68       0.86      0.01      0.01     11492\n",
      "          69       0.60      0.00      0.01       609\n",
      "          70       0.81      0.03      0.05     30671\n",
      "          71       0.96      0.02      0.05     12539\n",
      "          72       0.88      0.01      0.02      8419\n",
      "          73       1.00      0.02      0.04       814\n",
      "          74       1.00      0.00      0.00       410\n",
      "          75       0.94      0.10      0.19       456\n",
      "          76       0.91      0.01      0.03     11842\n",
      "          77       0.83      0.24      0.37     67343\n",
      "          78       0.79      0.03      0.06     50172\n",
      "          79       0.82      0.24      0.37     68914\n",
      "\n",
      "   micro avg       0.83      0.09      0.16    408771\n",
      "   macro avg       0.51      0.01      0.02    408771\n",
      "weighted avg       0.84      0.09      0.15    408771\n",
      " samples avg       0.24      0.09      0.13    408771\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "time: 1.16 s (started: 2021-10-31 12:13:22 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "cmSVM = classification_report(y_test, svmPreds)\n",
    "print(cmSVM)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1c5bb",
   "metadata": {},
   "source": [
    "**Observations**: \n",
    "\n",
    "    In above cell, SVM classification reprot is shown and the model's predictions are goos in terms of precision, all samples classified as the positive class are truly positive. Micro-averaging will put more emphasis on the common classes in the data set. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. \n",
    "    \n",
    "    In a multi-class classification setup, micro-average is are observed  more than macro averages. If we take precision for individual class the score is in acceptable range. The areas of improvement would be to use some other vectorizer or to use only three labels and exclude the age label from the multilabel. Here we are observing a system with high precision but low recall , returning very few results, but most of its predicted labels are correct when compared to the training labels. Since this  use case is a digital conntent, we can look at precision and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea012103",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFB1-yd12MOc",
    "outputId": "197ab0a0-891a-4e8c-d1c9-2955dcb27b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model prediction : ('Taurus', 'female', 'indUnk')\n",
      " model true label :  ('Taurus', 'female', 'indUnk')\n",
      "\n",
      " model prediction : ('Student', 'Virgo', 'female')\n",
      " model true label :  ('Student', 'Virgo', 'female')\n",
      "\n",
      " model prediction : ('Cancer', 'female', 'indUnk')\n",
      " model true label :  ('Cancer', 'female', 'indUnk')\n",
      "\n",
      " model prediction : ('Aries', 'female', 'indUnk')\n",
      " model true label :  ('Aries', 'female', 'indUnk')\n",
      "\n",
      " model prediction : ('Cancer', 'female', 'indUnk')\n",
      " model true label :  ('Cancer', 'female', 'indUnk')\n",
      "\n",
      " model prediction : ('Government', 'Taurus', 'male')\n",
      " model true label :  ('Government', 'Taurus', 'male')\n",
      "\n",
      " model prediction : ('Leo', 'female', 'indUnk')\n",
      " model true label :  ('Leo', 'female', 'indUnk')\n",
      "\n",
      "time: 10.3 s (started: 2021-10-31 12:57:08 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for i in [1016,1078,1361,1466,1659,1704,1744]:\n",
    "  print(\" model prediction :\", (binarizer.inverse_transform(svmPreds)[i]))\n",
    "  print(\" model true label : \", (binarizer.inverse_transform(y_test)[i]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51daa332",
   "metadata": {
    "id": "8ww1t1AYlzPs"
   },
   "source": [
    "**Observation**:\n",
    "    \n",
    "    As we can observe from above, there are many instances which are predicted by the model correctly. One few examples are shown above as mentioned in the task list. In this notebook, we have tried and test several models and with different data preprocessing methods. While building model and reading data, modin is used for prepration of dataframe instead of pandas. Modin run on the dask framework and it helps us to process the data in parallel. Modin uses Ray or Dask to provide an effortless way to speed up your pandas notebooks, scripts, and libraries. In this notebook, we have produced classification report which shows model performance. A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly.\n",
    "    \n",
    "    At first we tried with single label with count vectorizers method for data preprocessing. But Count vectorizer is unable to find the most important and less important word for analysis. As the name says, it just count the word occurance, although it works for few cases it has disadvantage as mentioned above.\n",
    "    \n",
    "    We tried with another vectorizer method - TF-IDF. TF-IDF enables us to gives us a way to associate each word in a document with a number that represents how relevant each word is in that document. This has improved model performance a bit and here we tried to classify for only one label at a time. The accruacy and precision for the model were calculated for each label [topic, age, gender, sign] individually.  Precision is one indicator of a machine learning model's performance – the quality of a positive prediction made by the model.  The precision for all the labels are in acceptable range, although accuracy has room for improvement. This is not the main model, as mentioned in the task list we need to merge the labels and then use multiclass classification to predict the labels.\n",
    "    \n",
    "    Finally, in this notebook, a multiclass classification algorithm is applied with logistic regression and SVM. Here SVM is having good score when compare with the  logistic regression. SVM is having 83%  micro avg precision and support is 408771 which is quite a good number. Support is the number of actual occurrences of the class in the specified dataset. The  macro avg is aroung 51% and weighted avg is 84%. Macro avg takes the average of the precision and recall of the system on different sets. Macro-average method can be used when you want to know how the system performs overall across the sets of data. Weighted-averaged, in here each classes's contribution to the average is weighted by its size. We can conclude that SVM is best classifier by far with all the observation stated above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d25424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50608ddd",
   "metadata": {
    "id": "8ww1t1AYlzPs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26adced",
   "metadata": {},
   "source": [
    "## Part 2 - Chatbot project for customer support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e82a60",
   "metadata": {},
   "source": [
    "**DOMAIN:**\n",
    "Customer support\n",
    "\n",
    "**CONTEXT:** \n",
    "\n",
    "Great Learning has a an academic support department which receives numerous support requests every day throughout the \n",
    "year. Teams are spread across geographies and try to provide support round the year. Sometimes there are circumstances where due to  heavy workload certain request resolutions are delayed, impacting company’s business. Some of the requests are very generic where a  proper resolution procedure delivered to the user can solve the problem. Company is looking forward to design an automation which can  interact with the user, understand the problem and display the resolution procedure [ if found as a generic request ] or redirect the request  to an actual human support executive if the request is complex or not in it’s database.\n",
    "\n",
    "**DATA DESCRIPTION:**\n",
    "\n",
    "A sample corpus is attached for your reference. Please enhance/add more data to the corpus using your linguistics \n",
    "skills.\n",
    "\n",
    "**PROJECT OBJECTIVE:**\n",
    "\n",
    "Design a python based interactive semi - rule based chatbot which can do the following: \n",
    "    \n",
    "    1. Start chat session with greetings and ask what the user is looking for.\n",
    "    2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus. \n",
    "    3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it.\n",
    "\n",
    "**EVALUATION:**\n",
    "\n",
    "GL evaluator will use linguistics to twist and turn sentences to ask questions on the topics described in DATA DESCRIPTION \n",
    "and check if the bot is giving relevant replies.\n",
    "\n",
    "**Hint:** There are a lot of techniques using which one can clean and prepare the data which can be used to train a ML/DL classifier. Hence, it might require you to experiment, \n",
    "research, self learn and implement the above classifier. There might be many iterations between hand building the corpus and designing the best fit text classifier. As the quality \n",
    "and quantity of corpus increases the model’s performance i.e. ability to answer right questions also increases. \n",
    "Reference: https://www.mygreatlearning.com/blog/basics-of-building-an-artificial-intelligence-chatbot/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511faf3",
   "metadata": {},
   "source": [
    "###### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9635eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ab202",
   "metadata": {},
   "source": [
    "###### reading from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb49901a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tag': 'Intro', 'patterns': ['hi', 'how are y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tag': 'Exit', 'patterns': ['thank you', 'tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tag': 'Olympus', 'patterns': ['olympus', 'ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tag': 'SL', 'patterns': ['i am not able to u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tag': 'NN', 'patterns': ['what is deep learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tag': 'Bot', 'patterns': ['what is your name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tag': 'Profane', 'patterns': ['what the hell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tag': 'Ticket', 'patterns': ['my problem is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             intents\n",
       "0  {'tag': 'Intro', 'patterns': ['hi', 'how are y...\n",
       "1  {'tag': 'Exit', 'patterns': ['thank you', 'tha...\n",
       "2  {'tag': 'Olympus', 'patterns': ['olympus', 'ex...\n",
       "3  {'tag': 'SL', 'patterns': ['i am not able to u...\n",
       "4  {'tag': 'NN', 'patterns': ['what is deep learn...\n",
       "5  {'tag': 'Bot', 'patterns': ['what is your name...\n",
       "6  {'tag': 'Profane', 'patterns': ['what the hell...\n",
       "7  {'tag': 'Ticket', 'patterns': ['my problem is ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "cb_df = pd.read_json('./GL_Bot.json')\n",
    "cb_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d40ea",
   "metadata": {},
   "source": [
    "    There are only 8 records, Here we need to map the intent of the users with responses. It is best to read the data in plain JSON format and then split the data based on tags in the JSON file.\n",
    "    For simple rule based chatbot we can utilize the  nltk.chat.util   utility to easy up process of building the chatbot. This needs data in certain format which we can plan to prepare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a148763",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_cb = cb_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6f4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recursively(search_dict, field):\n",
    "    \"\"\"\n",
    "    Takes a dict with nested lists and dicts,\n",
    "    and searches all dicts for a key of the field\n",
    "    provided.\n",
    "    \"\"\"\n",
    "    fields_found = []\n",
    "\n",
    "    for key, value in search_dict.items():\n",
    "\n",
    "        if key == field:\n",
    "            fields_found.append(value)\n",
    "\n",
    "        elif isinstance(value, dict):\n",
    "            results = get_recursively(value, field)\n",
    "            for result in results:\n",
    "                fields_found.append(result)\n",
    "\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    more_results = get_recursively(item, field)\n",
    "                    for another_result in more_results:\n",
    "                        fields_found.append(another_result)\n",
    "\n",
    "    return tuple(fields_found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f69f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_patterns = get_recursively(dic_cb,\"patterns\")\n",
    "list_of_responses = get_recursively(dic_cb,\"responses\")\n",
    "\n",
    "chatBot_list=[]\n",
    "for i in range(0,len(list_of_patterns)):\n",
    "    listToStr_prefix='r\"'\n",
    "    listToStr=''\n",
    "    for j in list_of_patterns[i]:\n",
    "        listToStr = ''.join([str(elem) for elem in j])\n",
    "        listToStr_prefix =   listToStr_prefix + \"|\" + listToStr\n",
    "    listToStr_prefix = listToStr_prefix  + '\"'\n",
    "    list_temp = [listToStr_prefix,list_of_responses[i]]\n",
    "    chatBot_list.append(list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cfac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am a chatbot assistant from great learning\n",
      ">hi\n",
      "Hello! how can i help you ?\n",
      ">How are you\n",
      "Hello! how can i help you ?\n",
      ">what is your name\n",
      "I am your virtual learning assistant\n",
      ">hours of working\n",
      "None\n",
      ">neural network\n",
      "None\n",
      ">artificial intelligence\n",
      "Link: Neural Nets wiki\n",
      ">softmax\n",
      "Link: Neural Nets wiki\n",
      ">ada boosting\n",
      "Link: Machine Learning wiki \n",
      ">supervised learning\n",
      "Link: Machine Learning wiki \n",
      ">no link visible on olympus\n",
      "Link: Olympus wiki\n",
      ">have a Good day\n",
      "I hope I was able to assist you, Good Bye\n",
      ">not helping\n",
      "None\n",
      ">my problem is not solved\n",
      "Tarnsferring the request to your PM\n",
      ">you are stupid\n",
      "Hello! how can i help you ?\n",
      ">you are a joke\n",
      "Hello! how can i help you ?\n",
      ">quit\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Hi! I am a chatbot assistant from great learning\")\n",
    "    chat = Chat(chatBot_list, reflections)\n",
    "    chat.converse()\n",
    "#initiate the conversation\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe90c83",
   "metadata": {},
   "source": [
    "    As we can observe this is a basic set up and needs a lot of improvement. This chat bot matches exact pattern in the intent and throws responses. There is no generalization involved in these chatbot and needs machine learning to be applied to improve performance. We can apply a simple neural network and check if the chatbot is giving  appropriate response after generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7134d",
   "metadata": {},
   "source": [
    "    lets create content using json file, we shall divide the data as X and Y variable for training purpose. Here we will have use the intent as X variable and Y as tags. From tags we will reterive the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3788ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./GL_Bot.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0429a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_list=[]\n",
    "Lable_list=[]\n",
    "\n",
    "doc_Xtrain = []\n",
    "doc_Ytrain = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for patterns in intent['patterns']:\n",
    "        word_temp = nltk.word_tokenize(patterns)\n",
    "        Word_list.extend(word_temp)\n",
    "        doc_Xtrain.append(word_temp)\n",
    "        doc_Ytrain.append(intent['tag'])\n",
    "        \n",
    "    if intent['tag'] not in Lable_list:\n",
    "        Lable_list.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748b1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.porter.PorterStemmer()\n",
    "# W = [ps.stem(w.lower()) for w in Word_list if w != \"?\"]\n",
    "Word_list = [w.lower() for w in Word_list if w != \"?\"]\n",
    "Word_list = sorted(list(set(Word_list)))\n",
    "Lable_list = sorted(Lable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce28224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Lable_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1a2f6",
   "metadata": {},
   "source": [
    "    Creating Bag Of Words for the input words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c2230cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = []\n",
    "Target = []\n",
    "\n",
    "out_array_zero = [0 for _ in range(len(Lable_list))]\n",
    "\n",
    "for x,doc in enumerate(doc_Xtrain):\n",
    "    bag=[]\n",
    "    w_temp = [w.lower() for w in doc]\n",
    "#     w_temp = [ps.stem(w.lower()) for w in doc]\n",
    "    \n",
    "    for w in Word_list:\n",
    "        if w in w_temp:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "            \n",
    "    output_row = out_array_zero[:]\n",
    "    output_row[Lable_list.index(doc_Ytrain[x])] = 1\n",
    "    \n",
    "    Train.append(bag)\n",
    "    Target.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38611f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 160)\n",
      "(128, 8)\n"
     ]
    }
   ],
   "source": [
    "bow_xtrain = np.asarray(Train)\n",
    "bow_ytrain = np.asarray(Target)\n",
    "print(bow_xtrain.shape)\n",
    "print(bow_ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5ec8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "SVC_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "SVC_pipeline.fit(bow_xtrain, bow_ytrain)\n",
    "# compute the testing accuracy\n",
    "prediction = SVC_pipeline.predict(bow_xtrain)\n",
    "print('Test accuracy is {}'.format(accuracy_score(bow_ytrain, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98af036",
   "metadata": {},
   "source": [
    "    This model looks like it is a overfitting one and hence we have to try with Neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "925303f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\modin\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                8050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 34,218\n",
      "Trainable params: 34,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "128/128 [==============================] - 0s 2ms/sample - loss: 2.0928 - acc: 0.1328\n",
      "Epoch 2/60\n",
      "128/128 [==============================] - 0s 125us/sample - loss: 2.0625 - acc: 0.1484\n",
      "Epoch 3/60\n",
      "128/128 [==============================] - 0s 203us/sample - loss: 2.0514 - acc: 0.1641\n",
      "Epoch 4/60\n",
      "128/128 [==============================] - 0s 203us/sample - loss: 2.0222 - acc: 0.2266\n",
      "Epoch 5/60\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.9986 - acc: 0.2266\n",
      "Epoch 6/60\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.9735 - acc: 0.3047\n",
      "Epoch 7/60\n",
      "128/128 [==============================] - 0s 242us/sample - loss: 1.9165 - acc: 0.4375\n",
      "Epoch 8/60\n",
      "128/128 [==============================] - 0s 211us/sample - loss: 1.9223 - acc: 0.3203\n",
      "Epoch 9/60\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 1.8686 - acc: 0.4141\n",
      "Epoch 10/60\n",
      "128/128 [==============================] - 0s 250us/sample - loss: 1.8498 - acc: 0.4141\n",
      "Epoch 11/60\n",
      "128/128 [==============================] - 0s 188us/sample - loss: 1.7992 - acc: 0.4531\n",
      "Epoch 12/60\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 1.7555 - acc: 0.4609\n",
      "Epoch 13/60\n",
      "128/128 [==============================] - 0s 125us/sample - loss: 1.7313 - acc: 0.4375\n",
      "Epoch 14/60\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 1.7270 - acc: 0.4844\n",
      "Epoch 15/60\n",
      "128/128 [==============================] - 0s 102us/sample - loss: 1.6686 - acc: 0.4844\n",
      "Epoch 16/60\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 1.6266 - acc: 0.5625\n",
      "Epoch 17/60\n",
      "128/128 [==============================] - 0s 94us/sample - loss: 1.5886 - acc: 0.5156\n",
      "Epoch 18/60\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 1.5846 - acc: 0.5469\n",
      "Epoch 19/60\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 1.4940 - acc: 0.6094\n",
      "Epoch 20/60\n",
      "128/128 [==============================] - 0s 125us/sample - loss: 1.4583 - acc: 0.6484\n",
      "Epoch 21/60\n",
      "128/128 [==============================] - 0s 126us/sample - loss: 1.4099 - acc: 0.6562\n",
      "Epoch 22/60\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.3369 - acc: 0.7188\n",
      "Epoch 23/60\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 1.3281 - acc: 0.6328\n",
      "Epoch 24/60\n",
      "128/128 [==============================] - 0s 211us/sample - loss: 1.2074 - acc: 0.7188\n",
      "Epoch 25/60\n",
      "128/128 [==============================] - 0s 187us/sample - loss: 1.1818 - acc: 0.7344\n",
      "Epoch 26/60\n",
      "128/128 [==============================] - 0s 203us/sample - loss: 1.1080 - acc: 0.7500\n",
      "Epoch 27/60\n",
      "128/128 [==============================] - 0s 219us/sample - loss: 1.0985 - acc: 0.7812\n",
      "Epoch 28/60\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.0691 - acc: 0.7734\n",
      "Epoch 29/60\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 0.9927 - acc: 0.8438\n",
      "Epoch 30/60\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 0.9691 - acc: 0.7891\n",
      "Epoch 31/60\n",
      "128/128 [==============================] - 0s 117us/sample - loss: 0.9404 - acc: 0.8125\n",
      "Epoch 32/60\n",
      "128/128 [==============================] - 0s 102us/sample - loss: 0.8035 - acc: 0.8438\n",
      "Epoch 33/60\n",
      "128/128 [==============================] - 0s 102us/sample - loss: 0.8144 - acc: 0.8359\n",
      "Epoch 34/60\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 0.7931 - acc: 0.8672\n",
      "Epoch 35/60\n",
      "128/128 [==============================] - 0s 125us/sample - loss: 0.7393 - acc: 0.8750\n",
      "Epoch 36/60\n",
      "128/128 [==============================] - 0s 141us/sample - loss: 0.6461 - acc: 0.9375\n",
      "Epoch 37/60\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 0.6458 - acc: 0.9219\n",
      "Epoch 38/60\n",
      "128/128 [==============================] - 0s 117us/sample - loss: 0.5820 - acc: 0.9297\n",
      "Epoch 39/60\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 0.5894 - acc: 0.8828\n",
      "Epoch 40/60\n",
      "128/128 [==============================] - 0s 141us/sample - loss: 0.4966 - acc: 0.9141\n",
      "Epoch 41/60\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 0.5374 - acc: 0.8750\n",
      "Epoch 42/60\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.5056 - acc: 0.9141\n",
      "Epoch 43/60\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 0.4873 - acc: 0.9297\n",
      "Epoch 44/60\n",
      "128/128 [==============================] - 0s 132us/sample - loss: 0.4573 - acc: 0.9297\n",
      "Epoch 45/60\n",
      "128/128 [==============================] - 0s 234us/sample - loss: 0.4159 - acc: 0.9531\n",
      "Epoch 46/60\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 0.3672 - acc: 0.9531\n",
      "Epoch 47/60\n",
      "128/128 [==============================] - 0s 219us/sample - loss: 0.3049 - acc: 0.9688\n",
      "Epoch 48/60\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 0.3264 - acc: 0.9609\n",
      "Epoch 49/60\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 0.3324 - acc: 0.9609\n",
      "Epoch 50/60\n",
      "128/128 [==============================] - 0s 187us/sample - loss: 0.3249 - acc: 0.9375\n",
      "Epoch 51/60\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 0.2349 - acc: 0.9766\n",
      "Epoch 52/60\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 0.2987 - acc: 0.9297\n",
      "Epoch 53/60\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 0.2155 - acc: 0.9766\n",
      "Epoch 54/60\n",
      "128/128 [==============================] - 0s 187us/sample - loss: 0.2712 - acc: 0.9766\n",
      "Epoch 55/60\n",
      "128/128 [==============================] - 0s 203us/sample - loss: 0.2174 - acc: 0.9844\n",
      "Epoch 56/60\n",
      "128/128 [==============================] - 0s 141us/sample - loss: 0.2175 - acc: 0.9766\n",
      "Epoch 57/60\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 0.1502 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 0.1976 - acc: 0.9844\n",
      "Epoch 59/60\n",
      "128/128 [==============================] - 0s 117us/sample - loss: 0.1731 - acc: 0.9609\n",
      "Epoch 60/60\n",
      "128/128 [==============================] - 0s 117us/sample - loss: 0.1841 - acc: 0.9766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x173ac6f45c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Start building a Keras Sequential Model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#Add hidden layers\n",
    "model.add(tf.keras.layers.Dense(160, activation='relu',input_shape =(160, )))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "#Add Output layer\n",
    "model.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(bow_xtrain, bow_ytrain,epochs=60, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638940d5",
   "metadata": {},
   "source": [
    "    Here the model is loss is reducing but the accuracy is close to 100%, so lets check the model performance with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da64b2",
   "metadata": {},
   "source": [
    "    Using BOW to create a vector which will be used to create model and we shall also check performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e7a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(inp,W):\n",
    "    w_temp1 = [ps.stem(w.lower()) for w in inp]\n",
    "    bag=[]\n",
    "    for w in W:\n",
    "        if w in w_temp1:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    return np.asarray(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25418dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First preferred tag for intent :: ['Whats up']  is  NN\n",
      "First preferred tag for intent :: ['Help']  is  Ticket\n",
      "First preferred tag for intent :: ['hi']  is  Intro\n",
      "First preferred tag for intent :: ['how are you']  is  NN\n",
      "First preferred tag for intent :: ['is anyone there']  is  NN\n",
      "First preferred tag for intent :: ['hello']  is  Intro\n",
      "First preferred tag for intent :: ['whats up']  is  NN\n",
      "First preferred tag for intent :: ['hey']  is  Intro\n",
      "First preferred tag for intent :: ['yo']  is  Intro\n",
      "First preferred tag for intent :: ['listen']  is  Intro\n",
      "First preferred tag for intent :: ['please help me']  is  NN\n",
      "First preferred tag for intent :: ['i am learner from']  is  NN\n",
      "First preferred tag for intent :: ['i belong to']  is  NN\n",
      "First preferred tag for intent :: ['aiml batch']  is  NN\n",
      "First preferred tag for intent :: ['aifl batch']  is  NN\n",
      "First preferred tag for intent :: ['i am from']  is  NN\n",
      "First preferred tag for intent :: ['my pm is']  is  NN\n",
      "First preferred tag for intent :: ['blended']  is  NN\n",
      "First preferred tag for intent :: ['online']  is  NN\n",
      "First preferred tag for intent :: ['i am from']  is  NN\n",
      "First preferred tag for intent :: ['hey ya']  is  NN\n",
      "First preferred tag for intent :: ['talking to you for first time']  is  NN\n"
     ]
    }
   ],
   "source": [
    "for i in [[\"Whats up\"],[\"Help\"],[\"hi\"] ,[\"how are you\"] ,[\"is anyone there\"] ,[\"hello\"] ,[\"whats up\"],[\"hey\"],[\"yo\"],[\"listen\"] ,[\"please help me\"],[\"i am learner from\"],[\"i belong to\"],[\"aiml batch\"],[\"aifl batch\"],[\"i am from\"],[\"my pm is\"],[\"blended\"],[\"online\"] ,[\"i am from\"],[\"hey ya\"],[\"talking to you for first time\"]]:\n",
    "    input_as_bow = np.asarray(bag_of_words(i,Word_list))\n",
    "    input_as_bow_reshaped = input_as_bow.reshape(1,160)\n",
    "    prediction = model.predict(input_as_bow_reshaped)\n",
    "    #below code can be used to check second preference of the bot\n",
    "    #flat=model.predict(input_as_bow_reshaped).flatten()\n",
    "    #flat.sort()\n",
    "    #print(\"Second preferred tag for intent :: \", i , \" is \", Lable_list[int(np.where(prediction==flat[-2])[1])])\n",
    "    print(\"First preferred tag for intent ::\", i , \" is \" , Lable_list[np.argmax(model.predict(input_as_bow_reshaped))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e5673",
   "metadata": {},
   "source": [
    "    The model seems to be working fine but we can improvise by trying different vectorization mechanism. We shall use TFIDF and one-hot encoding on the tag to get better result. Bag of words seems to be very basic way and TF-IDF may help us imprvise the chabot system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83bd9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#One hot encoding the input vector - tag\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "y = np.array(doc_Ytrain)\n",
    "y = y.reshape(-1,1)\n",
    "encoder.fit(y)\n",
    "y_oh = encoder.transform(y).toarray()\n",
    "print(y_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4520759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time', 'thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy', 'olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus', 'i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters', 'what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'sgd', 'what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours', 'what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit', 'my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket']\n"
     ]
    }
   ],
   "source": [
    "#creating corpus in below cell\n",
    "cr = []\n",
    "for i in doc_Xtrain:\n",
    "    a = ' '.join([str(elem) for elem in i]) \n",
    "    cr.append(a)\n",
    "    \n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba926de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 159)\n"
     ]
    }
   ],
   "source": [
    "#vectorizing the corpus\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = cr\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "iX = vectorizer.fit_transform(corpus)\n",
    "print(iX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3632cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 157)\t0.4960467936046329\n",
      "  (0, 59)\t0.6536437985925223\n",
      "  (0, 11)\t0.5715657119842836\n"
     ]
    }
   ],
   "source": [
    "#checking the exa\n",
    "inpX = vectorizer.transform([\"how are you\"])\n",
    "print(inpX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eca50114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 159)               25440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 159)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                8000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 408       \n",
      "=================================================================\n",
      "Total params: 33,848\n",
      "Trainable params: 33,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "128/128 [==============================] - 0s 1ms/sample - loss: 2.0786 - acc: 0.1953\n",
      "Epoch 2/40\n",
      "128/128 [==============================] - 0s 141us/sample - loss: 2.0674 - acc: 0.1562\n",
      "Epoch 3/40\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 2.0423 - acc: 0.2500\n",
      "Epoch 4/40\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 2.0285 - acc: 0.1797\n",
      "Epoch 5/40\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 2.0152 - acc: 0.2500\n",
      "Epoch 6/40\n",
      "128/128 [==============================] - 0s 242us/sample - loss: 1.9830 - acc: 0.2812\n",
      "Epoch 7/40\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 1.9589 - acc: 0.3047\n",
      "Epoch 8/40\n",
      "128/128 [==============================] - 0s 195us/sample - loss: 1.9498 - acc: 0.2812\n",
      "Epoch 9/40\n",
      "128/128 [==============================] - 0s 188us/sample - loss: 1.8932 - acc: 0.3125\n",
      "Epoch 10/40\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.8937 - acc: 0.3359\n",
      "Epoch 11/40\n",
      "128/128 [==============================] - 0s 211us/sample - loss: 1.8646 - acc: 0.3516\n",
      "Epoch 12/40\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 1.8251 - acc: 0.3516\n",
      "Epoch 13/40\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 1.8185 - acc: 0.3750\n",
      "Epoch 14/40\n",
      "128/128 [==============================] - 0s 133us/sample - loss: 1.7611 - acc: 0.4141\n",
      "Epoch 15/40\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.7410 - acc: 0.3984\n",
      "Epoch 16/40\n",
      "128/128 [==============================] - 0s 156us/sample - loss: 1.6964 - acc: 0.3750\n",
      "Epoch 17/40\n",
      "128/128 [==============================] - 0s 187us/sample - loss: 1.6665 - acc: 0.4375\n",
      "Epoch 18/40\n",
      "128/128 [==============================] - 0s 141us/sample - loss: 1.6370 - acc: 0.4375\n",
      "Epoch 19/40\n",
      "128/128 [==============================] - 0s 242us/sample - loss: 1.5775 - acc: 0.4688\n",
      "Epoch 20/40\n",
      "128/128 [==============================] - 0s 187us/sample - loss: 1.5286 - acc: 0.5547\n",
      "Epoch 21/40\n",
      "128/128 [==============================] - 0s 203us/sample - loss: 1.5283 - acc: 0.5156\n",
      "Epoch 22/40\n",
      "128/128 [==============================] - 0s 148us/sample - loss: 1.4733 - acc: 0.5625\n",
      "Epoch 23/40\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 1.4070 - acc: 0.5781\n",
      "Epoch 24/40\n",
      "128/128 [==============================] - 0s 203us/sample - loss: 1.3576 - acc: 0.6406\n",
      "Epoch 25/40\n",
      "128/128 [==============================] - 0s 156us/sample - loss: 1.2842 - acc: 0.7266\n",
      "Epoch 26/40\n",
      "128/128 [==============================] - 0s 156us/sample - loss: 1.2427 - acc: 0.6484\n",
      "Epoch 27/40\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 1.1792 - acc: 0.7109\n",
      "Epoch 28/40\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 1.1757 - acc: 0.7266\n",
      "Epoch 29/40\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 1.1222 - acc: 0.7656\n",
      "Epoch 30/40\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 1.0663 - acc: 0.7344\n",
      "Epoch 31/40\n",
      "128/128 [==============================] - 0s 188us/sample - loss: 0.9728 - acc: 0.8203\n",
      "Epoch 32/40\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 0.8970 - acc: 0.8516\n",
      "Epoch 33/40\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 0.9039 - acc: 0.8125\n",
      "Epoch 34/40\n",
      "128/128 [==============================] - 0s 195us/sample - loss: 0.8929 - acc: 0.8359\n",
      "Epoch 35/40\n",
      "128/128 [==============================] - 0s 172us/sample - loss: 0.7776 - acc: 0.8828\n",
      "Epoch 36/40\n",
      "128/128 [==============================] - 0s 156us/sample - loss: 0.7171 - acc: 0.8984\n",
      "Epoch 37/40\n",
      "128/128 [==============================] - 0s 180us/sample - loss: 0.6690 - acc: 0.8906\n",
      "Epoch 38/40\n",
      "128/128 [==============================] - 0s 164us/sample - loss: 0.7065 - acc: 0.8828\n",
      "Epoch 39/40\n",
      "128/128 [==============================] - 0s 188us/sample - loss: 0.5542 - acc: 0.9297\n",
      "Epoch 40/40\n",
      "128/128 [==============================] - 0s 188us/sample - loss: 0.5712 - acc: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x173aab76b70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#building a Keras Sequential Model\n",
    "tf.keras.backend.clear_session()\n",
    "model1 = tf.keras.Sequential()\n",
    "\n",
    "#Add hidden layers\n",
    "model1.add(tf.keras.layers.Dense(159, activation='relu',input_shape =(159, )))\n",
    "model1.add(tf.keras.layers.Dropout(0.4))\n",
    "model1.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model1.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "#Add Output layer\n",
    "model1.add(tf.keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "model1.fit(iX,y_oh,epochs=40, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ae282",
   "metadata": {},
   "source": [
    "    This model is having good accuracy and the loss is also decreasing. Observing both loss and accuracy, the model would perform better than rule based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec95bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting responses for the tag\n",
    "def reply_responses(pred_tag):\n",
    "    for tg in data[\"intents\"]:\n",
    "        if tg['tag'] == pred_tag:\n",
    "            responses = tg['responses']\n",
    "            return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fce2c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ::  ['thank you']\n",
      "Predicted tag :: Exit\n",
      "Response ::  ['I hope I was able to assist you, Good Bye']\n"
     ]
    }
   ],
   "source": [
    "#Check for single input\n",
    "inp1=[\"thank you\"]\n",
    "inpX = vectorizer.transform(inp1)\n",
    "pred_tag = (Lable_list[np.argmax(model1.predict(inpX))])\n",
    "        \n",
    "print(\"Input :: \", inp1)\n",
    "print(\"Predicted tag ::\", pred_tag)\n",
    "print(\"Response :: \", reply_responses(pred_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abaa9a",
   "metadata": {},
   "source": [
    "    Checking model performance for multiple input in below few cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "775cfca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For intent  ['Whats up'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['Help'] , tag is  Ticket  and Response ::  ['Tarnsferring the request to your PM']\n",
      "For intent  ['hi'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['how are you'] , tag is  Profane  and Response ::  ['Please use respectful words']\n",
      "For intent  ['is anyone there'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['hello'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['whats up'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['hey'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['yo'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['listen'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['please help me'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['i am learner from'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['i belong to'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['aiml batch'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['aifl batch'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['i am from'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['my pm is'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['blended'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['online'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['i am from'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['hey ya'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n",
      "For intent  ['talking to you for first time'] , tag is  Intro  and Response ::  ['Hello! how can i help you ?']\n"
     ]
    }
   ],
   "source": [
    "for i in [[\"Whats up\"],[\"Help\"],[\"hi\"] ,[\"how are you\"] ,[\"is anyone there\"] ,[\"hello\"] ,[\"whats up\"],[\"hey\"],[\"yo\"],[\"listen\"] ,[\"please help me\"],[\"i am learner from\"],[\"i belong to\"],[\"aiml batch\"],[\"aifl batch\"],[\"i am from\"],[\"my pm is\"],[\"blended\"],[\"online\"] ,[\"i am from\"],[\"hey ya\"],[\"talking to you for first time\"]]:\n",
    "    inpX = vectorizer.transform(i)\n",
    "    pred_tag = Lable_list[np.argmax(model1.predict(inpX))]\n",
    "    print(\"For intent \", i ,\", tag is \" , pred_tag, \" and Response :: \", reply_responses(pred_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78e5da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For intent  ['thank you'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['thanks'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['cya'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['see you'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['later'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['see you later'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['goodbye'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['i am leaving'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['have a Good day'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['you helped me'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['thanks a lot'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['thanks'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['you are the best'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['great help'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['too good'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n",
      "For intent  ['you are a good learning buddy'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']\n"
     ]
    }
   ],
   "source": [
    "for i in [[\"thank you\"] ,[\"thanks\"] ,[\"cya\"],[\"see you\"],[\"later\"] ,[\"see you later\"] ,[\"goodbye\"] ,[\"i am leaving\"] ,[\"have a Good day\"],[\"you helped me\"],[\"thanks a lot\"],[\"thanks\"],[\"you are the best\"],[\"great help\"],[\"too good\"],[\"you are a good learning buddy\"]]:\n",
    "    inpX = vectorizer.transform(i)\n",
    "    pred_tag = Lable_list[np.argmax(model1.predict(inpX))]\n",
    "    print(\"For intent \", i ,\", tag is \" , pred_tag , \" and Response :: \", reply_responses(pred_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd341f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For intent  ['explain me how olympus works'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['I am not able to understand olympus'] , tag is  SL  and Response ::  ['Link: Machine Learning wiki ']  \n",
      "\n",
      "For intent  ['olympus window not working'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['no access to olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['unable to see link in olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['no link visible on olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['whom to contact for olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['lot of problem with olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['olypus is not a good tool'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['lot of problems with olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['how to use olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['teach me olympus'] , tag is  Olympus  and Response ::  ['Link: Olympus wiki']  \n",
      "\n",
      "For intent  ['thank you'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['thanks'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['cya'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['see you'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['later'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['see you later'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['goodbye'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['i am leaving'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['have a Good day'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['you helped me'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['thanks a lot'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['thanks a ton'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['you are the best'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['great help'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['too good'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n",
      "For intent  ['you are a good learning buddy'] , tag is  Exit  and Response ::  ['I hope I was able to assist you, Good Bye']  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [[\"explain me how olympus works\"],[\"I am not able to understand olympus\"],[\"olympus window not working\"],[\"no access to olympus\"],[\"unable to see link in olympus\"],[\"no link visible on olympus\"],[\"whom to contact for olympus\"],[\"lot of problem with olympus\"],[\"olypus is not a good tool\"],[\"lot of problems with olympus\"],[\"how to use olympus\"],[\"teach me olympus\"],[\"thank you\"] ,[\"thanks\"] ,[\"cya\"],[\"see you\"],[\"later\"] ,[\"see you later\"] ,[\"goodbye\"] ,[\"i am leaving\"] ,[\"have a Good day\"],[\"you helped me\"],[\"thanks a lot\"],[\"thanks a ton\"],[\"you are the best\"],[\"great help\"],[\"too good\"],[\"you are a good learning buddy\"]]:\n",
    "    inpX = vectorizer.transform(i)\n",
    "    pred_tag = Lable_list[np.argmax(model1.predict(inpX))]\n",
    "    print(\"For intent \", i ,\", tag is \" ,pred_tag , \" and Response :: \", reply_responses(pred_tag) , \" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c166e",
   "metadata": {},
   "source": [
    "    Building a chat bot in below cell and checking few inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "407e64cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am a chatbot assistant from great learning with Trained model\n",
      "hello\n",
      "['Hello! how can i help you ?']\n",
      "create a ticket\n",
      "['Tarnsferring the request to your PM']\n",
      "adam\n",
      "['Link: Neural Nets wiki']\n",
      "sigmoid\n",
      "['Link: Neural Nets wiki']\n",
      "adaboost\n",
      "['Link: Neural Nets wiki']\n",
      "ada\n",
      "['Link: Machine Learning wiki ']\n",
      "bagging\n",
      "['Link: Machine Learning wiki ']\n",
      "you are a joke\n",
      "['Please use respectful words']\n",
      "what is the meaning of deep learning\n",
      "['Link: Neural Nets wiki']\n",
      "how deep learning is linked to AI\n",
      "['Link: Neural Nets wiki']\n",
      "you are a joke\n",
      "['Please use respectful words']\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Hi! I am a chatbot assistant from great learning with Trained model\")\n",
    "    while True:\n",
    "        user_input = input()\n",
    "        if user_input == \"quit\":\n",
    "            break\n",
    "        # output\n",
    "        inpX = vectorizer.transform([user_input])\n",
    "        pred_tag = Lable_list[np.argmax(model1.predict(inpX))]\n",
    "        print(reply_responses(pred_tag))\n",
    "    \n",
    "#initiate the conversation\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b10e4a",
   "metadata": {},
   "source": [
    "    This model is having pretty good performance and the responses which are received after changing sentence are coming as per expectation. The chatbot responses can be improved by application of sequence to sequence model. For developing Seq2Seq AI Chatbot, We can look into encoder-decoder attention mechanism architecture. This encoder-decoder is using Recurrent Neural Network with LSTM (Long-Short-Term-Memory) cells.\n",
    "    \n",
    "    We can also look into the Generative models which are quite intelligent. They generate a response, word by word based on the query. These models are difficult to train, as they need to learn the proper sentence structure by themselves. But once trained it can give an impression of talking with a human for the user.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6eba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d025a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
